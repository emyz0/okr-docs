# ğŸ–¼ï¸ Qwen3 VLM Server

Qwen/Qwen3-VL-4B-Instruct modeli ile PDF'lerdeki gÃ¶rsel, tablo, diagram ve grafikleri analiz eden FastAPI sunucusu.

## ğŸ“‹ Gereksinimler

- **Python:** 3.10+
- **RAM:** ~12-16GB (CPU), 8-10GB (GPU)
- **GPU (opsiyonel):** CUDA 11.8+ (Ã§ok daha hÄ±zlÄ±)

## ğŸš€ Kurulum

### Otomatik Kurulum (Ã–nerilen)

```bash
chmod +x setup_vlm.sh
./setup_vlm.sh
```

### Manuel Kurulum

```bash
# Virtual environment oluÅŸtur
python3 -m venv vlm_env

# AktifleÅŸtir (macOS/Linux)
source vlm_env/bin/activate

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r vlm_requirements.txt
```

## â–¶ï¸ Sunucu BaÅŸlatma

```bash
# Virtual environment'i aktifleÅŸtir
source vlm_env/bin/activate

# Server Ã§alÄ±ÅŸtÄ±r
python3 vlm_server.py
```

Ã‡Ä±ktÄ±:
```
INFO:     Uvicorn running on http://0.0.0.0:8001
```

### Arka Planda Ã‡alÄ±ÅŸtÄ±rma

```bash
nohup python3 vlm_server.py > vlm.log 2>&1 &
```

## ğŸ¥ Sunucu SaÄŸlÄ±ÄŸÄ± KontrolÃ¼

```bash
curl http://localhost:8001/health

# Ã–rnek Ã§Ä±ktÄ±:
{
  "status": "healthy",
  "model": "Qwen/Qwen3-VL-4B-Instruct",
  "device": "cuda",
  "model_loaded": true
}
```

## ğŸ“¨ API KullanÄ±mÄ±

### POST /analyze

GÃ¶rselleri analiz eder - tablo, diagram, grafik vb. Ã§Ä±karÄ±r.

**Ä°stek:**
```json
{
  "image_base64": "iVBORw0KGgoAAAANS...",  // Base64 encoded image
  "task": "extract",  // "extract", "describe", "table", "diagram"
  "language": "turkish"
}
```

**YanÄ±t:**
```json
{
  "task": "extract",
  "analysis": "GÃ¶rselde bir tablo vardÄ±r. Ä°Ã§eriÄŸi ÅŸu ÅŸekildedir:\n\n| SÃ¼tun1 | SÃ¼tun2 |\n|--------|--------|\n| DeÄŸer1 | DeÄŸer2 |",
  "confidence": 0.95,
  "content_type": "table"
}
```

### GET /health

Sunucu durumunu kontrol eder.

## ğŸ”Œ NextJS Ä°ntegrasyonu

Upload route (`/app/api/rag/upload/route.ts`) otomatik olarak:

1. PDF dosyasÄ± yÃ¼klenir
2. Metin Ã§Ä±karÄ±lÄ±r (PDFLoader)
3. Her sayfa VLM ile analiz edilir (tablo, diagram vb.)
4. SonuÃ§lar chunks olarak veritabanÄ±na kaydedilir

**AkÄ±ÅŸ:**
```
PDF Upload
  â”œâ”€ Text Extract (PDFLoader) âœ…
  â”œâ”€ VLM Analysis (Qwen3-VL-4B)
  â”‚   â”œâ”€ Sayfa 1 â†’ Render â†’ Analyze
  â”‚   â”œâ”€ Sayfa 2 â†’ Render â†’ Analyze
  â”‚   â””â”€ Sayfa N (max 20)
  â””â”€ Database
      â”œâ”€ Text chunks
      â””â”€ VLM chunks (tablo, diagram)
```

## ğŸ“Š Ä°Ã§erik TÃ¼rleri

VLM sonuÃ§larÄ±nda `content_type` ÅŸu deÄŸerleri alabilir:

- **text**: Normal metin
- **table**: Tablo (Markdown formatÄ±nda)
- **diagram**: Diyagram/Åekil (aÃ§Ä±klamasÄ±)
- **chart**: Grafik (aÃ§Ä±klamasÄ±)

## âš¡ Performans

### Benchmark (Ã–rnek DeÄŸerler)

| Device | Model Load | Per Page | 20 Pages |
|--------|-----------|----------|----------|
| CPU (8 core) | 3-5 min | 10-20s | 3-6 min |
| GPU (RTX 3090) | 1-2 min | 2-3s | 40-60s |

**Optimizasyon Ä°puÃ§larÄ±:**
1. GPU kullan (5-10x daha hÄ±zlÄ±)
2. Flash Attention 2 (CUDA ile otomatik)
3. float16 (CUDA ile otomatik)

## ğŸ› ï¸ Sorun Giderme

### "Model yÃ¼klenmedi" HatasÄ±

```
âŒ Status: model_loaded: false
```

**Ã‡Ã¶zÃ¼m:**
- Sunucunun 5-10 dakika beklemesi gerekebilir (model indirme + yÃ¼kleme)
- Logs'u kontrol et: `tail -f vlm.log`

### "CUDA out of memory" HatasÄ±

```
RuntimeError: CUDA out of memory
```

**Ã‡Ã¶zÃ¼m:**
- CPU mode'da Ã§alÄ±ÅŸtÄ±r (daha yavaÅŸ)
- Batch size azalt
- float16 kullan (otomatik)

### Sunucu baÅŸlatÄ±lmÄ±yor

```bash
# Debug mode'da Ã§alÄ±ÅŸtÄ±r
python3 -u vlm_server.py

# Logs'Ä± kontrol et
tail -f vlm.log
```

## ğŸ“ Log DosyalarÄ±

Arka planda Ã§alÄ±ÅŸan server logs:
```bash
tail -f vlm.log
```

## ğŸ§¹ Temizleme

```bash
# Virtual environment kaldÄ±r
rm -rf vlm_env

# Logs kaldÄ±r
rm vlm.log

# Hugging Face cache kaldÄ±r
rm -rf ~/.cache/huggingface/hub/
```

## ğŸ“š Ä°lgili Kaynaklar

- [Qwen3 VLM Docs](https://huggingface.co/Qwen/Qwen3-VL-4B-Instruct)
- [FastAPI Docs](https://fastapi.tiangolo.com)
- [Transformers Docs](https://huggingface.co/docs/transformers)

## ğŸ¤ Support

Sorunlar iÃ§in:
1. Logs'u kontrol et (`vlm.log`)
2. Health endpoint test et
3. Python/PyTorch versiyonlarÄ±nÄ± kontrol et

---

**YapÄ±landÄ±rma DosyalarÄ±:**
- `vlm_server.py` - Ana VLM server uygulamasÄ±
- `vlm_requirements.txt` - Python baÄŸÄ±mlÄ±lÄ±klarÄ±
- `setup_vlm.sh` - Otomatik kurulum betiÄŸi
- `/lib/rag/pdf-vlm-analyzer.ts` - NextJS integration library
