#!/usr/bin/env python3
"""
ğŸ–¼ï¸ QWEN VLM SERVER - HUGGING FACE INFERENCE API (OpenAI Compatible)
Hugging Face router.huggingface.co API'si ile Qwen Vision Language Model'i Ã§alÄ±ÅŸtÄ±rÄ±r
Model: Qwen/Qwen2-VL-32B-Instruct (32 Milyar parametre)

OpenAI client'i kullanÄ±yor (HF router'Ä± OpenAI-compatible endpoint sunuyor)
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional
import base64
from io import BytesIO
from PIL import Image
import logging
import os
import json
from dotenv import load_dotenv
from openai import OpenAI

# .env.local dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# Logging ayarla
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Qwen VLM Server (HF Inference)", version="2.0")

# Hugging Face API anahtarÄ±
HF_API_KEY = os.getenv("HUGGINGFACE_API_KEY")
if not HF_API_KEY:
    logger.warning("âš ï¸ HUGGINGFACE_API_KEY environment variable set edilmedi!")
    logger.warning("   .env.local dosyasÄ±na ekle: HUGGINGFACE_API_KEY=hf_...")

# Model seÃ§im
MODEL_ID = "Qwen/Qwen2-VL-32B-Instruct"  # 32B Vision Language Model

# OpenAI-compatible client (HF router endpoint'ine)
client = OpenAI(
    base_url="https://router.huggingface.co/v1",
    api_key=HF_API_KEY,
)

logger.info(f"ğŸ–¼ï¸ Model: {MODEL_ID}")
logger.info(f"   Provider: HuggingFace Router (OpenAI-compatible)")

class VLMRequest(BaseModel):
    """VLM analiz isteÄŸi"""
    image_base64: str  # Base64 encoded image
    task: str = "extract"  # "extract", "describe", "table", "diagram"
    language: str = "turkish"  # "turkish", "english"

class VLMResponse(BaseModel):
    """VLM analiz yanÄ±tÄ±"""
    task: str
    analysis: str
    confidence: float
    content_type: str  # "text", "table", "diagram", "chart", "mixed"

async def call_hf_inference(image: Image.Image, prompt: str) -> str:
    """
    Hugging Face Router API'ye Ã§aÄŸrÄ± yap (OpenAI-compatible)
    
    Args:
        image: PIL Image object
        prompt: Metin talimatÄ±
    
    Returns:
        Model'in yanÄ±tÄ± (string)
    """
    if not HF_API_KEY:
        raise HTTPException(
            status_code=500,
            detail="HUGGINGFACE_API_KEY ayarlanmadÄ±. .env.local dosyasÄ±na ekle"
        )
    
    try:
        # Image'i base64'e encode et
        buffer = BytesIO()
        image.save(buffer, format="JPEG", quality=95)
        buffer.seek(0)
        image_base64 = base64.b64encode(buffer.read()).decode("utf-8")
        
        logger.info(f"ğŸ“¡ HF Router'a istek gÃ¶nderiliyor...")
        
        # OpenAI client kullanarak VLM Ã§aÄŸrÄ±sÄ± yap
        completion = client.chat.completions.create(
            model=MODEL_ID,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=512,
            temperature=0.2,
        )
        
        analysis = completion.choices[0].message.content
        
        logger.info(f"âœ… Analiz baÅŸarÄ±lÄ±: {analysis[:100]}...")
        return analysis
        
    except Exception as e:
        logger.error(f"âŒ HF Router API Ã§aÄŸrÄ± hatasÄ±: {str(e)}")
        raise HTTPException(status_code=500, detail=f"API hatasÄ±: {str(e)}")

@app.post("/analyze", response_model=VLMResponse)
async def analyze_image(request: VLMRequest) -> VLMResponse:
    """
    GÃ¶rsel analiz yap - tablo, diagram, metin Ã§Ä±kar
    (HF Inference API kullanarak)
    
    Args:
        request.image_base64: Base64 encoded gÃ¶rsel
        request.task: Ne yapÄ±lacak (extract, describe, table, diagram)
        request.language: Hangi dilde sonuÃ§ istediÄŸimiz
    
    Returns:
        VLMResponse: Analiz sonucu
    """
    try:
        logger.info(f"ğŸ–¼ï¸ GÃ¶rsel analizi baÅŸladÄ± (task={request.task})")
        
        # Base64'ten gÃ¶rsele dÃ¶nÃ¼ÅŸtÃ¼r
        image_data = base64.b64decode(request.image_base64)
        image = Image.open(BytesIO(image_data)).convert("RGB")
        
        # GÃ¶rev spesifik prompt'lar
        prompts = {
            "extract": "Bu gÃ¶rselde tablo var mÄ±? Diyagram var mÄ±? Grafik var mÄ±? Sadece ÅŸu cevaplardan birini ver: 'TABLO', 'DIYAGRAM', 'GRAFIK', 'METIN'. BaÅŸka birÅŸey yazma!",
            "describe": "Bu gÃ¶rseli kÄ±saca aÃ§Ä±kla. Ne gÃ¶rmektedir? TÃ¼rkÃ§e olarak cevap ver.",
            "table": "Bu gÃ¶rselde tablo var mÄ±? Varsa tablo iÃ§eriÄŸini Markdown formatÄ±nda gÃ¶ster. TÃ¼rkÃ§e olarak cevap ver.",
            "diagram": "Bu gÃ¶rselde diyagram, grafik veya ÅŸekil var mÄ±? Varsa ne anlattÄ±ÄŸÄ±nÄ± aÃ§Ä±kla. TÃ¼rkÃ§e olarak cevap ver.",
        }
        
        prompt = prompts.get(request.task, prompts["extract"])
        
        # HF Inference API'ye Ã§aÄŸrÄ± yap
        analysis = await call_hf_inference(image, prompt)
        
        # Ä°Ã§erik tÃ¼rÃ¼nÃ¼ belirle
        analysis_lower = analysis.lower()
        
        if "tablo" in analysis_lower:
            content_type = "table"
        elif "diyagram" in analysis_lower or "ÅŸema" in analysis_lower:
            content_type = "diagram"
        elif "grafik" in analysis_lower or "chart" in analysis_lower:
            content_type = "chart"
        else:
            content_type = "text"
        
        logger.info(f"âœ… Analiz tamamlandÄ± (type={content_type})")
        
        return VLMResponse(
            task=request.task,
            analysis=analysis,
            confidence=0.95,  # HF daha gÃ¼venilir
            content_type=content_type
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Analiz hatasÄ±: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Analiz hatasÄ±: {str(e)}")

@app.get("/health")
async def health():
    """Sunucu saÄŸlÄ±k kontrolÃ¼"""
    return {
        "status": "healthy",
        "model": MODEL_ID,
        "type": "hugging_face_inference",
        "api_key_set": HF_API_KEY is not None
    }

@app.get("/")
async def root():
    """Ana sayfa"""
    return {
        "name": "Qwen VLM Server (HF Inference)",
        "version": "2.0",
        "model": MODEL_ID,
        "type": "hugging_face_inference_api",
        "endpoints": [
            "/analyze (POST) - GÃ¶rsel analiz et",
            "/health (GET) - Sunucu durumu"
        ]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
