// ===== CHAIN.TS =====
// RAG sisteminin merkezi bileÅŸenleri (AI models, text splitter)
// Bu dosya tÃ¼m iÅŸlemlerde kullanÄ±lan shared objects'leri export eder

import { OpenAIEmbeddings } from "@langchain/openai";
import { PGVectorStore } from "@langchain/community/vectorstores/pgvector";
import { ChatOpenAI } from "@langchain/openai";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { Document } from "@langchain/core/documents";

// â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
// â•‘                    RAG SÄ°STEMÄ°NÄ°N KRÄ°TÄ°K BÄ°LEÅENLERÄ°                      â•‘
// â•‘                                                                            â•‘
// â•‘ Bu dosya RAG (Retrieval-Augmented Generation) pipelineinin temel           â•‘
// â•‘ bileÅŸenlerini baÅŸlatÄ±r ve export eder.                                    â•‘
// â•‘                                                                            â•‘
// â•‘ PIPELINE: Soru â†’ Embedding â†’ Vector Search â†’ Reranking â†’ LLM â†’ Cevap      â•‘
// â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”´ KRÄ°TÄ°K NOKTA #1: EMBEDDINGS (VEKTÃ–R DÃ–NÃœÅÃœMÃœ)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 
// AMAÃ‡: Metni sayÄ±sal vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rme
// NEDEN Ã–NEMLI: Benzer metinler benzer vektÃ¶rler Ã¼retir â†’ similarity search
// 
// TEKNIK DETAYLAR:
// - text-embedding-3-small: 1536-boyutlu vektÃ¶r Ã¼retir
// - Cosine similarity: VektÃ¶rler arasÄ±ndaki benzerliÄŸi 0-1 arasÄ± Ã¶lÃ§er
// - "cat" ve "dog" vektÃ¶rleri birbirine yakÄ±n (ikisi de hayvan)
// - "cat" ve "trigonometry" vektÃ¶rleri Ã§ok uzak
//
// SEÃ‡ME KRÄ°TERLERÄ°:
// - text-embedding-3-small: HÄ±zlÄ±, ucuz, yeterli kalite (â­ Ã–NERÄ°LEN)
// - text-embedding-3-large: Daha iyi kalite, ama 3x pahalÄ± ve yavaÅŸ
// 
// SORUN SENARYOLARI:
// âŒ Model deÄŸiÅŸtirirsen: Eski embedding'lerle yeni model incompat
// âŒ Dimension mismatch: pgvector(1536) â‰  embedding(3072) â†’ crash
// âŒ API key yok: OpenAI'dan embedding alÄ±namaz
//
// Ã‡Ã–ZÃœMLERI:
// âœ… Ã‡alÄ±ÅŸan embedding modeli yap
// âœ… Dimension'Ä± kontrol et (ALTER TABLE documents ALTER COLUMN embedding TYPE vector(3072))
// âœ… Env variable'Ä± set et (OPENAI_API_KEY)
//
export const embeddings = new OpenAIEmbeddings({
  apiKey: process.env.OPENAI_API_KEY!,
  modelName: "text-embedding-3-small", // â­ HÄ±zlÄ± ve ekonomik seÃ§enek
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”´ KRÄ°TÄ°K NOKTA #2: LLM (DILE GELÄ°ÅTÄ°RME MODELÄ°)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// AMAÃ‡: Sorulara cevap Ã¼retme (doÄŸal dil ile)
// NEDEN Ã–NEMLI: CevapÄ±n kalitesi tamamen LLM'e baÄŸlÄ±
//
// TEKNIK DETAYLAR:
// - gpt-4o-mini: Dengeli model (gÃ¼Ã§ + hÄ±z + cost)
// - temperature: 0.2 = deterministik (her zaman benzer cevaplar)
// - System role: Model'e talimatlarÄ± "siz bir asistansÄ±nÄ±z" ÅŸeklinde verir
//
// SEÃ‡ME KRÄ°TERLERÄ°:
// - gpt-4o-mini: â­ Ã–NERÄ°LEN (RAG iÃ§in ideal balans)
// - gpt-4o: Daha gÃ¼Ã§lÃ¼ ama 5x pahalÄ±
// - gpt-3.5-turbo: Ucuz ama dÃ¼ÅŸÃ¼k kalite
//
// TEMPERATURE SEÃ‡Ä°MÄ°:
// - 0.0: HiÃ§ randomluk yok (deterministic)
//   â†’ "Ne zaman sorsam aynÄ± cevap alÄ±rÄ±m" (iyi)
// - 0.5: Orta rastgelelik
// - 1.0: Ã‡ok rastgele (creative)
//   â†’ "Her seferinde farklÄ± cevap alÄ±rÄ±m" (RAG'da kÃ¶tÃ¼)
// â†’ RAG'da 0.2 tercih edilir (tutarlÄ±lÄ±k Ã¶nemli)
//
// SORUN SENARYOLARI:
// âŒ API key yok: OpenAI'dan cevap alÄ±namaz
// âŒ Rate limit: Ã‡ok hÄ±zlÄ± Ã§ok istek â†’ 429 hatasÄ±
// âŒ Token limit: Prompt + context Ã§ok uzun â†’ error
// âŒ Context kurma baÅŸarÄ±sÄ±z: Sistem talimatlarÄ± yok â†’ ÅŸaÅŸÄ±rÄ±r
//
// Ã‡Ã–ZÃœMLERI:
// âœ… Env variable set et (OPENAI_API_KEY)
// âœ… Ä°stek aralÄ±klarÄ±nÄ± ayarla
// âœ… Context'i sÄ±nÄ±rla (max 4000 karakter)
// âœ… Prompt template'ini iyileÅŸtir
//
export const llm = new ChatOpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
  modelName: "gpt-4o-mini", // â­ Balans: gÃ¼Ã§ + hÄ±z + maliyet
  temperature: 0.1, // Deterministik (tutarlÄ± cevaplar)
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”´ KRÄ°TÄ°K NOKTA #3: TEXT SPLITTER (METNI PARÃ‡ALAMA)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// AMAÃ‡: Uzun metni yÃ¶netilebilir parÃ§alara (chunk'lara) bÃ¶lme
// NEDEN Ã–NEMLI: Embedding modeli Ã§ok uzun metni iÅŸleyemez
//
// TEKNIK DETAYLAR:
// - chunkSize: 1000 = her chunk maksimum 1000 karakter
// - chunkOverlap: 200 = chunk'lar arasÄ±nda 200 karakterlik Ã¶rtÃ¼ÅŸme
// - Overlap neden gerekli? SÄ±nÄ±r noktasÄ±nda context kaybÄ±nÄ± Ã¶nlemek
//
// Ã–RNEK SENARYO:
// Metin: "...Bu bÃ¶lÃ¼mÃ¼n sonunda Ã¶nemli bilgi var. Bu bilgi devamÄ±nda..."
// chunkSize=1000, chunkOverlap=200 ise:
//   Chunk 1: "...Bu bÃ¶lÃ¼mÃ¼n sonunda Ã¶nemli bilgi var. [200 char...]"
//   Chunk 2: "[...200 char...] Bu bilgi devamÄ±nda... [next chunk]"
//   â†’ SÄ±nÄ±r noktasÄ±nda bilgi tekrarlanarak kayÄ±p engellenir!
//
// SEÃ‡ME KRÄ°TERLERÄ°:
// âŒ chunkSize=500: Ã‡ok kÃ¼Ã§Ã¼k â†’ Ã§ok fazla chunk â†’ yavaÅŸ ve pahalÄ±
// âŒ chunkSize=3000: Ã‡ok bÃ¼yÃ¼k â†’ context kaybÄ±
// âœ… chunkSize=1000: Ä°deal (PDF'ler iÃ§in)
//
// âŒ chunkOverlap=0: SÄ±nÄ±r noktasÄ±nda bilgi kayÄ±p
// âŒ chunkOverlap=500: Ã‡ok fazla tekrar â†’ fazla embedding
// âœ… chunkOverlap=200: Ä°deal (20% overlap)
//
// SORUN SENARYOLARI:
// âŒ Chunk Ã§ok kÃ¼Ã§Ã¼k: Cevap parÃ§alanmÄ±ÅŸ, tutarsÄ±z
// âŒ Chunk Ã§ok bÃ¼yÃ¼k: Ä°lgisiz bilgi karÄ±ÅŸÄ±yor
// âŒ Overlap yok: CÃ¼mlelerin ortasÄ± kesilir
//
// Ã‡Ã–ZÃœMLERI:
// âœ… chunkSize ayarla (500-2000 arasÄ± test et)
// âœ… chunkOverlap'i 10-30% arasÄ± tut
// âœ… Separator Ã¶zelleÅŸtir (if needed)
//
export const textSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1000, // â­ Her parÃ§a maksimum 1000 karakter
  chunkOverlap: 200, // â­ 200 karakterlik Ã¶rtÃ¼ÅŸme (%20)
});

// ===== 4. FUNCTION: DOCUMENT INGEST (METIN YÃœKLEME) =====
// Metin veya dokÃ¼manlarÄ± iÅŸleyip PostgreSQL'e kaydeder
// KullanÄ±m: API yanÄ±tlarÄ±, web iÃ§eriÄŸi, ham metin vb. yÃ¼klemek iÃ§in
export async function ingestDocument(params: {
  text: string;                              // Ä°ÅŸlenecek metin
  metadata: Record<string, any>;             // Kaynak bilgisi (title, author vs.)
  userId: string;                            // Hangi kullanÄ±cÄ± iÃ§in
}) {
  const { text, metadata, userId } = params;

  // 1. Metin parÃ§alarÄ±na bÃ¶l
  // textSplitter.createDocuments(): Metin + metadata'yÄ± dokuman objelerine dÃ¶nÃ¼ÅŸtÃ¼r
  const docs = await textSplitter.createDocuments([text], [metadata]);

  // 2. TÃ¼m dokÃ¼manlara userId ekle (farklÄ± kullanÄ±cÄ±larÄ± ayÄ±rt etmek iÃ§in)
  const docsWithUser = docs.map(
    (doc) =>
      new Document({
        pageContent: doc.pageContent,
        metadata: { ...(doc.metadata as any), userId }, // userId'yi metadata'ya ekle
      })
  );

  // 3. PostgreSQL ile baÄŸlantÄ± baÅŸlat ve dokÃ¼manlarÄ± ekle
  // PGVectorStore: LangChain'in PostgreSQL vector desteÄŸi
  // - Otomatik embedding Ã¼retir
  // - Otomatik vektÃ¶rleri DB'ye kaydeder
  const store = await PGVectorStore.initialize(embeddings, {
    postgresConnectionOptions: {
      connectionString: process.env.POSTGRES_URL!, // DB baÄŸlantÄ± stringi
    },
    tableName: "documents",   // Verilerin kaydedileceÄŸi tablo
    schemaName: "public",     // Database schema
  });

  // DokÃ¼manlarÄ± DB'ye ekle
  await store.addDocuments(docsWithUser);

  return { success: true, chunks: docsWithUser.length };
}

// ===== 5. FUNCTION: RAG SORGUSU (SORU-CEVAP) =====
// KullanÄ±cÄ±nÄ±n sorusuna cevap bulur ve kaynaklarÄ± dÃ¶ndÃ¼rÃ¼r
// Pipeline: Soru â†’ Embedding â†’ Similarity Search â†’ LLM â†’ Cevap
export async function queryRAG(params: {
  question: string; // KullanÄ±cÄ±nÄ±n sorusu
  userId: string;   // Hangi kullanÄ±cÄ±nÄ±n verilerine sor
}) {
  const { question, userId } = params;

  // 1. PostgreSQL ile baÄŸlantÄ± kur
  const store = await PGVectorStore.initialize(embeddings, {
    postgresConnectionOptions: {
      connectionString: process.env.POSTGRES_URL!,
    },
    tableName: "documents",
    schemaName: "public",
  });

  // 2. Vector similarity search: Soruya en benzer 4 dokuman bul
  // similaritySearch(): Soru embedding'ini hesapla ve DB'de ara
  const relevantDocs = await store.similaritySearch(question, 4);

  // EÄŸer hiÃ§ benzer dokuman bulunamadÄ±ysa
  if (relevantDocs.length === 0) {
    return { answer: "Bu konu hakkÄ±nda bilgim yok.", sources: [] };
  }

  // 3. LLM iÃ§in context hazÄ±rla (bulunan dokÃ¼manlarÄ± birleÅŸtir)
  // DokÃ¼mantlarÄ± "---" ile ayÄ±rarak LLM'e sunar
  const context = relevantDocs.map((d) => d.pageContent).join("\n\n---\n\n");

  // 4. LLM iÃ§in prompt oluÅŸtur
  // Prompt: talimat + context + soru = LLM'in soruyu cevaplamasÄ±
  const prompt = `AÅŸaÄŸÄ±daki bilgileri kullanarak soruyu cevapla. Bilgi yoksa uydurma:

${context}

Soru: ${question}

Cevap:`;

  // 5. LLM'i Ã§alÄ±ÅŸtÄ±r
  const res = await llm.invoke(prompt);

  // 6. Cevap + kaynaklarÄ± dÃ¶ndÃ¼r
  return {
    answer: res.content,           // LLM'in Ã¼rettiÄŸi cevap
    sources: relevantDocs.map((d) => d.metadata), // Hangi dokÃ¼manlardan aldÄ±ÄŸÄ±
  };
}
