// Next.js API Route: /api/rag/upload endpoint'i
// POST isteÄŸini handle eder ve FARKLI DOSYA TIPLERINI iÅŸler
// Desteklenen formatlar: PDF, Excel (.xlsx, .xls), Word (.docx), Text (.txt)
import { NextRequest, NextResponse } from 'next/server'
import { PDFLoader } from '@langchain/community/document_loaders/fs/pdf'
import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters'
import { OpenAIEmbeddings } from "@langchain/openai"
import { pool } from '@/lib/rag/db'
import { recognizeImageText } from '@/lib/rag/pdf-ocr-processor'
import fs from 'fs'
import path from 'path'
import { extractTextFromExcel, extractTextFromWord, extractTextFromTxt } from '@/lib/rag/document-parser'

export async function POST(req: NextRequest) {
  // FormData'yÄ± parse et (dosyalarÄ± ve userId'yi oku)
  const formData = await req.formData()
  // formData.getAll('files'): SeÃ§ilen tÃ¼m PDF dosyalarÄ±nÄ± array olarak dÃ¶ndÃ¼rÃ¼r
  const files = formData.getAll('files') as File[]
  // userId: Hangi kullanÄ±cÄ± iÃ§in dosya yÃ¼kleniyorsa onun ID'si
  const userId = formData.get('userId')?.toString() || 'demo-user'

  // Validasyon: En az 1 PDF dosyasÄ± seÃ§ilmiÅŸ mi?
  if (!files || files.length === 0) {
    return NextResponse.json({ error: 'PDF bulunamadÄ±' }, { status: 400 })
  }

  console.log('Upload baÅŸladÄ±:', { userId, fileCount: files.length })

  try {
    // OpenAI embedding modeli baÅŸlat
    // text-embedding-3-small: KÃ¼Ã§Ã¼k ve hÄ±zlÄ± model (1536 boyutlu vektÃ¶r Ã¼retir)
    const embeddings = new OpenAIEmbeddings({
      apiKey: process.env.OPENAI_API_KEY!,
      modelName: "text-embedding-3-small",
    })

    // Her dosya iÃ§in ayrÄ± bir veri array'i tutuyoruz (chunk'larÄ± dosya baÅŸÄ±na sayabilmek iÃ§in)
    const allDocs: Array<{file: string, doc: any}> = []

    // âœ… HER DOSYA TIPINI Ä°ÅLE (PDF, Excel, Word, TXT)
    for (const file of files) {
      try {
        // DosyayÄ± buffer'a dÃ¶nÃ¼ÅŸtÃ¼r
        const arrayBuffer = await file.arrayBuffer()
        const buffer = Buffer.from(arrayBuffer)

        // GeÃ§ici dosya oluÅŸtur /tmp klasÃ¶rÃ¼nde
        // Dosya adÄ±nda boÅŸluk ve special karakterleri underscore ile deÄŸiÅŸtir
        const sanitizedName = file.name
          .replace(/\s+/g, '_')  // BoÅŸluklarÄ± underscore yap
          .replace(/[^\w.-]/g, '_')  // Word karakterleri, nokta, tire hariÃ§ hepsini underscore yap
        const tempPath = path.join('/tmp', sanitizedName)
        console.log(`ğŸ“ Temp dosya: ${tempPath}`)
        fs.writeFileSync(tempPath, buffer)
        
        // DosyanÄ±n yazÄ±ldÄ±ÄŸÄ±nÄ± kontrol et
        if (!fs.existsSync(tempPath)) {
          console.error(`âŒ Dosya yazÄ±lamadÄ±: ${tempPath}`)
          continue
        }
        console.log(`âœ… Dosya yazÄ±ldÄ±: ${fs.statSync(tempPath).size} byte`)

        const ext = path.extname(file.name).toLowerCase()
        let docs: any[] = []

        // ğŸ“„ DOSYA TIPINE GÃ–RE Ä°ÅLE
        if (ext === '.pdf') {
          // PDF iÅŸleme
          const loader = new PDFLoader(tempPath)
          docs = await loader.load()
          console.log(`ğŸ“‘ PDF: ${file.name} - ${docs.length} sayfa`)
          
          // ğŸ–¼ï¸ OCR ile gÃ¶rselleri de oku
          try {
            const { extractOCRFromPdf } = await import('@/lib/rag/pdf-image-ocr')
            const ocrResults = await extractOCRFromPdf(tempPath, 20) // Ä°lk 20 sayfa
            
            if (ocrResults.length > 0) {
              console.log(`âœ… OCR: ${ocrResults.length} sayfadan metin Ã§Ä±karÄ±ldÄ±`)
              
              // OCR sonuÃ§larÄ±nÄ± dokÃ¼manlara ekle
              ocrResults.forEach((ocr) => {
                docs.push({
                  pageContent: `[OCR - Sayfa ${ocr.pageNum}]\n${ocr.text}`,
                  metadata: {
                    source: file.name,
                    type: 'ocr',
                    page: ocr.pageNum,
                    confidence: ocr.confidence,
                    has_images: true
                  }
                })
              })
              
              console.log(`ğŸ“Š OCR chunk'larÄ± eklendi: toplam ${docs.length} dokuman`)
            }
          } catch (ocrError) {
            console.warn(`âš ï¸  OCR hatasÄ± (devam etme): ${ocrError}`)
          }
        } 
        else if (ext === '.xlsx' || ext === '.xls') {
          // Excel iÅŸleme
          const excelText = await extractTextFromExcel(tempPath)
          if (excelText) {
            docs = [{
              pageContent: excelText,
              metadata: { source: file.name, type: 'excel' }
            }]
            console.log(`ğŸ“Š Excel: ${file.name} - 1 dokuman (${excelText.length} karakter)`)
          }
        }
        else if (ext === '.docx') {
          // Word iÅŸleme
          const wordText = await extractTextFromWord(tempPath)
          if (wordText) {
            docs = [{
              pageContent: wordText,
              metadata: { source: file.name, type: 'word' }
            }]
            console.log(`ğŸ“ Word: ${file.name} - 1 dokuman`)
          }
        } 
        else if (ext === '.txt') {
          // Text iÅŸleme
          const txtText = await extractTextFromTxt(tempPath)
          if (txtText) {
            docs = [{
              pageContent: txtText,
              metadata: { source: file.name, type: 'text' }
            }]
            console.log(`ğŸ“„ Text: ${file.name} - 1 dokuman`)
          }
        }

        if (docs.length === 0) {
          console.warn(`âš ï¸  ${file.name}: Dokuman Ã§Ä±karÄ±lamadÄ±`)
          continue
        }

        // Excel dosyalarÄ± iÃ§in satÄ±rlarÄ± ayÄ±r (CSV satÄ±rlarÄ±nÄ± dokÃ¼manlara bÃ¶l)
        if (ext === '.xlsx' || ext === '.xls') {
          // CSV satÄ±rlarÄ±nÄ± dokÃ¼manlara dÃ¶nÃ¼ÅŸtÃ¼r
          const lines = docs[0].pageContent.split('\n').filter((line: string) => line.trim())
          const splitExcelDocs = lines.map((line: string, idx: number) => ({
            pageContent: line,
            metadata: {
              source: file.name,
              file_type: ext,
              page_index: idx + 1,
              has_images: false
            }
          }))
          allDocs.push(...splitExcelDocs.map((doc: any) => ({ file: file.name, doc })))
          continue
        }

        // ğŸ“‹ METADATA'YA KAYNAK BÄ°LGÄ°SÄ° EKLE (PDF, Word, TXT iÃ§in)
        const docsWithSource = docs.map((d, pageIdx) => {
          const meta = (d.metadata as any) || {}
          
          // GÃ¶rselleri algÄ±la
          const hasImages = d.pageContent.includes('[Image]') || 
                           d.pageContent.includes('table') ||
                           d.pageContent.includes('Tablo')
          
          return {
            ...d,
            metadata: { 
              ...meta, 
              source: file.name,
              file_type: ext,  // Dosya tipi
              has_images: hasImages,
              page_index: pageIdx + 1
            },
          }
        })
        
        allDocs.push(...docsWithSource.map(doc => ({ file: file.name, doc })))

        // GeÃ§ici dosyayÄ± sil
        fs.unlinkSync(tempPath)
      } catch (fileError: any) {
        console.error(`âŒ ${file.name} iÅŸleme hatasÄ±: ${fileError.message}`)
        // Hata olsa da devam et
      }
    }

    // Metin splitter baÅŸlat
    // Uzun metni daha kÃ¼Ã§Ã¼k parÃ§alara (chunk'lara) bÃ¶ler
    const splitter = new RecursiveCharacterTextSplitter({
      chunkSize: 1000,        // Her chunk maksimum 1000 karakter
      chunkOverlap: 200,      // Chunk'lar arasÄ±nda 200 karakter Ã¶rtÃ¼ÅŸme (context kaybÄ±nÄ± azaltmak iÃ§in)
    })
    
    // Her dosya iÃ§in ayrÄ± chunk'lama yap
    // BÃ¶ylece her dosyanÄ±n chunk'larÄ± 1'den baÅŸlayarak numaralanÄ±r
    const splitDocs: any[] = []
    // Dosya ismine gÃ¶re dokÃ¼mantlarÄ± gruplaÅŸtÄ±r
    const fileMap = new Map<string, any[]>()
    
    // allDocs'taki tÃ¼m dokÃ¼mantlarÄ± dosya ismine gÃ¶re grupla
    for (const { file, doc } of allDocs) {
      if (!fileMap.has(file)) fileMap.set(file, [])
      fileMap.get(file)!.push(doc)
    }
    
    // Her dosya grubunu ayrÄ± ayrÄ± chunk'la
    for (const [file, fileDocs] of fileMap.entries()) {
      // Bu dosyaya ait dokÃ¼mantlarÄ± chunk'la
      const fileChunks = await splitter.splitDocuments(fileDocs)
      // Her chunk'a 1'den baÅŸlayan numara ver (bu dosya iÃ§in)
      fileChunks.forEach((chunk, idx) => {
        chunk.metadata = { ...chunk.metadata, chunk: idx + 1 }
        splitDocs.push(chunk)
      })
    }

    // PostgreSQL'e kaydet
    // TÃ¼m chunk'larÄ± veritabanÄ±na insert et
    let insertedCount = 0
    
    // ğŸ†” Her dosya grubu iÃ§in file_id'yi bir kez belirle
    const fileIdMap = new Map<string, number>()
    for (const [file, ] of fileMap.entries()) {
      // Bu dosya iÃ§in file_id'yi belirle (MAX + 1)
      const result = await pool.query(
        'SELECT COALESCE(MAX(file_id), 0) + 1 as next_file_id FROM documents WHERE user_id = $1',
        [userId]
      )
      fileIdMap.set(file, result.rows[0].next_file_id)
      console.log(`ğŸ“ ${file}: file_id = ${result.rows[0].next_file_id}`)
    }
    
    for (let i = 0; i < splitDocs.length; i++) {
      const doc = splitDocs[i]
      // Metadata'dan bilgiler oku
      const baseMeta = (doc.metadata as any) || {}
      // PDF'in hangi sayfasÄ±ndan geldiÄŸini belirle
      const page = baseMeta.loc?.pageNumber ?? baseMeta.page ?? 'N/A'
      // SatÄ±r numarasÄ±nÄ± belirle (eÄŸer varsa)
      const lineNumber = baseMeta.loc?.lines?.from ?? 'N/A'
      // Chunk numarasÄ± daha Ã¶nce set edilmiÅŸ, onu koru
      const chunkNum = baseMeta.chunk || 'N/A'
      // Metadata'yÄ± hazÄ±rla
      doc.metadata = { ...baseMeta, chunk: chunkNum, page, lineNumber }
      
      try {
        // Bu chunk'Ä± embedding modeline gÃ¶nder (vektÃ¶r halinde kodla)
        // Ã–nce metni temizle: null karakterleri ve kontrol karakterlerini kaldÄ±r
        let cleanContent = doc.pageContent
          .replace(/\u0000/g, '')           // Null karakterleri kaldÄ±r
          .replace(/[\x00-\x1F\x7F]/g, '')  // Kontrol karakterlerini kaldÄ±r
          .replace(/[\uFEFF]/g, '')          // BOM karakterini kaldÄ±r
          .replace(/[^\x20-\x7E\xA0-\xFF]/g, '') // BaskÄ± yapÄ±lamayan karakterleri kaldÄ±r
          .trim();
        
        // BoÅŸ metin kontrol et
        if (!cleanContent) {
          console.warn('âš ï¸ Chunk temizlendikten sonra boÅŸ');
          continue;
        }
        
        const embedding = await embeddings.embedQuery(cleanContent)
        
        // Embedding baÅŸarÄ±lÄ± mÄ± kontrol et
        if (!embedding || embedding.length === 0) {
          console.error(' Embedding boÅŸ:', cleanContent.substring(0, 50))
          continue
        }

        console.log(' Embedding boyutu:', embedding.length, 'User:', userId)
        
        // Metadata'yÄ± da temizle (null karakterleri kaldÄ±r)
        let cleanMetadata = JSON.stringify(doc.metadata)
          .replace(/\u0000/g, '')
          .replace(/[\x00-\x1F\x7F]/g, '')
          .replace(/[\uFEFF]/g, '')
          .replace(/[^\x20-\x7E\xA0-\xFF]/g, '');
        
        // JSON geÃ§erliliÄŸini kontrol et
        try {
          JSON.parse(cleanMetadata);
        } catch (e) {
          console.warn('âš ï¸ Metadata JSON hata, temizleniyor');
          cleanMetadata = JSON.stringify({ source: doc.metadata?.source || 'unknown', chunk: doc.metadata?.chunk || 'N/A' });
        }
        
        // VeritabanÄ±na insert et
        // ğŸ†” file_id: Her dosya iÃ§in SABIT (tÃ¼m chunks bu ID'yi paylaÅŸÄ±r)
        // file_id dosya baÅŸÄ±nda belirlenmiÅŸ ve map'te tutuluyor
        const fileId = fileIdMap.get(doc.metadata.source) || 1
        const result = await pool.query(
          `INSERT INTO public.documents (user_id, content, metadata, embedding, file_id)
           VALUES ($1, $2, $3::jsonb, $4::vector, $5)
           RETURNING id, file_id`,
          [userId, cleanContent, cleanMetadata, JSON.stringify(embedding), fileId]
        )
        insertedCount++
        console.log(` Chunk kaydedildi: ID=${result.rows[0]?.id}, FileID=${result.rows[0]?.file_id}`)
      } catch (insertErr: any) {
        // EÄŸer bu chunk insert edilemezse, hata yaz ama devam et
        console.error(' Chunk insert hatasÄ±:', insertErr.message)
        console.error('   Error Code:', insertErr.code)
        console.error('   SQL:', insertErr.detail)
      }
    }

    // BaÅŸarÄ± cevabÄ± dÃ¶ndÃ¼r
    // KaÃ§ chunk'Ä±n baÅŸarÄ±yla kaydedildiÄŸini bildir
    return NextResponse.json({ 
      success: true, 
      count: insertedCount,
      message: ` ${insertedCount}/${splitDocs.length} chunk baÅŸarÄ±yla kaydedildi`
    })
  } catch (err: any) {
    console.error('YÃ¼kleme hatasÄ±:', err)
    return NextResponse.json({ error: err.message || 'Ä°ÅŸleme hatasÄ±' }, { status: 500 })
  }
}
