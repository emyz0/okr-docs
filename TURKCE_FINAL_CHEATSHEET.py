#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“‹ TÃœRKÃ‡E FINAL CHEATSHEET - Ä°nterview & Production Ready
"""

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 ğŸš€ ÃœRETIM HAZIR - TÃœRKÃ‡E Ã–ZET                               â•‘
â•‘                  RAG Sistemi - Bilmen Gerekenler                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Œ Ã–N KÃ–ÅESÄ°: BÄ°LMEN GEREKEN 5 ÅEY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“¢ GÃœNCELLEMELER (28 KasÄ±m 2025)

- VLM: `vlm_server.py` gÃ¼ncellendi â€” HuggingFace Router (OpenAI-compatible) kullanÄ±larak
   `Qwen/Qwen2-VL-32B-Instruct` modeline istek atÄ±lÄ±yor (`router.huggingface.co/v1`).
- Reranker: Eski Cohere fallback'Ä± kaldÄ±rÄ±ldÄ±. `lib/rag/rerank.ts` silindi.
   Fallback artÄ±k `app/api/rag/query/route.ts` iÃ§inde pozisyona dayalÄ± (1 - index*0.05).
- DB: `lib/rag/schema.sql` Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±; `documents` tablosu oluÅŸturuldu ve chunk'lar DB'ye kay
   dediliyor.
- Prompt context excerpt uzunluÄŸu `600` â†’ `2000` karaktere Ã§Ä±karÄ±ldÄ± (tablolar daha gÃ¶rÃ¼nÃ¼r).

1ï¸âƒ£ PROBLEM:
   Åirket PDF'lerini LLM bilmiyor â†’ HalÃ¼sinasyon yapÄ±yor
   Ã‡Ã¶zÃ¼m: RAG sistemi PDF'leri getiriyor â†’ LLM doÄŸru cevap veriyor

2ï¸âƒ£ Ä°KÄ° AÅAMALI FÄ°LTRELEME:
   AÅŸama 1: pgvector    (85% doÄŸruluk, <10ms)    â†’ 10 belge
   AÅŸama 2: Reranker    (99% doÄŸruluk, 2-4s)     â†’ En iyi 3 belge
   
   Neden ikisi? pgvector hÄ±zlÄ± ama yÃ¼ksek yanlÄ±ÅŸ
   Reranker doÄŸru ama yavaÅŸ. Beraber = hÄ±zlÄ± + doÄŸru

3ï¸âƒ£ BACKUP PLANI (FALLBACK):
   Normal: Query â†’ Embedding â†’ pgvector â†’ Reranker â†’ LLM
   ArÄ±za:  Query â†’ Embedding â†’ pgvector â†’ Yedek â†’ LLM
   
   Fallback formÃ¼lÃ¼: skor = 1 - (index * 0.05)
   SonuÃ§: %99 â†’ %85 doÄŸruluk ama SÄ°STEM HÄ°Ã‡ BOZULMAZ

4ï¸âƒ£ COHERE KALDIRILDÎ™:
   Eski: Cohere API ($10-30/ay)
   Yeni: Vector similarity fallback (Ã¼cretsiz)
   Fark: Daha hÄ±zlÄ±, daha ucuz, daha gÃ¼venilir

5ï¸âƒ£ BÄ°LEÅENLER:
   ğŸ”¹ Embedding:   OpenAI (1536 boyut)
   ğŸ”¹ VeritabanÄ±:  PostgreSQL + pgvector
   ğŸ”¹ Reranker:    Qwen3-Reranker-4B (port 8000)
   ğŸ”¹ LLM:         gpt-4o-mini (sÄ±caklÄ±k: 0.1)
   ğŸ”¹ GeÃ§miÅŸ:      PostgreSQL JSONB (Ã§ok turlu sohbet)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” HER BÄ°LEÅENÄ° ANLAMA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€ EMBEDDING (Metni SayÄ±ya Ã‡evir) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Ne:       "Python nedir?" â†’ [0.1, 0.2, ..., 0.8] (1536 sayÄ±)
Neden:    Metni doÄŸrudan karÅŸÄ±laÅŸtÄ±ramayÄ±z. SayÄ±larÄ± matematikle karÅŸÄ±laÅŸtÄ±rÄ±rÄ±z
NasÄ±l:    OpenAI API (~50ms)
FormÃ¼l:   Kosinus BenzerliÄŸi = (A Â· B) / (||A|| Ã— ||B||) = -1 ile 1 arasÄ±

Ã–rnek:
  Query: "Python nedir?"
         â†“
         Embedding: [0.123, 0.456, ..., 0.789]
         
  Benzer soru: "Python programlama dili"
               â†“
               Embedding: [0.125, 0.458, ..., 0.791]
               
  Kosinus benzerliÄŸi â‰ˆ 0.99 (Ã§ok benzer!)

Ã–nemli: AynÄ± embedding modeli kullanÄ±rsan sonuÃ§lar tutarlÄ± olur.

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ PGVECTOR ARAMA (HÄ±zlÄ± Filtre) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Ne:       PostgreSQL extension'u. Milyonlardan 10 en benzer belgeyi bul
Neden:    HÄ±zlÄ±. Matematiksel olarak optimized.
NasÄ±l:    <-> operator (Euclidean uzaklÄ±ÄŸÄ±)
Kod:      SELECT * FROM documents
          ORDER BY embedding <-> query_vector
          LIMIT 10

SonuÃ§:    10 belge sÄ±ralÄ± (en benzer â†’ en farklÄ±)
Problem:  "Python nedir?" sorusu iÃ§in
          "Ben Python'u nefret ediyorum" yazÄ±sÄ± da Ã¼st sÄ±ralara Ã§Ä±kabilir
          (Ã‡Ã¼nkÃ¼ "Python" kelimesini gÃ¶rÃ¼yor, ama negatif sentiment'i anlamÄ±yor)

HÄ±z:      <10ms (Ã§ok hÄ±zlÄ±!)
DoÄŸruluk: ~85% (iyi ama mÃ¼kemmel deÄŸil)

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ RERANKER (Qwen3-Reranker-4B) - SEMANTIC SIRALA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Ne:       BERT-like model. 10 belgeyi semantic'e gÃ¶re yeniden sÄ±rala
Neden:    pgvector sadece word similarity'e bakÄ±yor. Reranker baÄŸlamÄ± anlamÄ±yor.
NasÄ±l:    Her [Query, Document] Ã§iftini karÅŸÄ±laÅŸtÄ±r â†’ P(ilgili) hesapla
HÄ±z:      2-4 saniye (yavaÅŸ)
DoÄŸruluk: ~99% (muazzam!)

Ã–rnek:
  pgvector sÄ±ralamasÄ±:
    1. "Python tutorial" (distance: 0.05) âœ…
    2. "Programlama temelleri" (distance: 0.10) âœ…
    3. "Ben Python'u nefret ediyorum" (distance: 0.12) âŒ YANLIÅ!
    4. "Java vs Python" (distance: 0.15) âœ…
  
  Reranker sÄ±ralamasÄ±:
    1. "Python tutorial" (skor: 0.98) âœ… (mÃ¼kemmel eÅŸleÅŸme)
    2. "Java vs Python" (skor: 0.87) âœ… (karÅŸÄ±laÅŸtÄ±rma)
    3. "Programlama temelleri" (skor: 0.75) âœ… (genel bilgi)
    4. "Ben Python'u nefret ediyorum" (skor: 0.12) âœ… (arkaya alÄ±ndÄ±!)

Konum:    FastAPI server, port 8000
Kod:      app/api/rag/query/route.ts satÄ±rlarÄ± 76-88

UyarÄ±:    Reranker Ã§alÄ±ÅŸmazsa sorular yavaÅŸlÄ±yor!

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ FALLBACK MEKANIZMI (Backup PlanÄ±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Ne:       Reranker server down ise vektÃ¶r benzerliÄŸine dayanarak score ver
FormÃ¼l:   skor = 1 - (index * 0.05)

Hesaplamalar:
  Index 0 â†’ 1 - (0 Ã— 0.05) = 1.00  â† pgvector'Ã¼n en iyisi (en benzer)
  Index 1 â†’ 1 - (1 Ã— 0.05) = 0.95
  Index 2 â†’ 1 - (2 Ã— 0.05) = 0.90
  Index 3 â†’ 1 - (3 Ã— 0.05) = 0.85  â† Hala iyi
  Index 4 â†’ 1 - (4 Ã— 0.05) = 0.80
  Index 5 â†’ 1 - (5 Ã— 0.05) = 0.75  â† Orta
  Index 6 â†’ 1 - (6 Ã— 0.05) = 0.70
  Index 7 â†’ 1 - (7 Ã— 0.05) = 0.65
  Index 8 â†’ 1 - (8 Ã— 0.05) = 0.60
  Index 9 â†’ 1 - (9 Ã— 0.05) = 0.55  â† En uzak (en farklÄ±)

Neden iÅŸe yarar:
  1. pgvector zaten iyi sÄ±ralÄ± (en benzer Ã¶nde)
  2. Bu sÄ±ralamayÄ± score'a Ã§eviriyoruz
  3. HiÃ§bir ÅŸey bozulmaz!

DoÄŸruluk:  %99 â†’ %85 (dÃ¼ÅŸÃ¼ÅŸ var ama sistem ayakta kalÄ±yor)
Trade-off: Biraz daha dÃ¼ÅŸÃ¼k kalite vs. %100 uptime

Kod:      app/api/rag/query/route.ts satÄ±rlarÄ± 99-110

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ LLM (gpt-4o-mini) - Cevap OluÅŸtur â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Model:    OpenAI gpt-4o-mini
Neden:    Ä°yi kalite, uygun fiyat, TÃ¼rkÃ§e desteÄŸi
SÄ±caklÄ±k: 0.1 (faktual, yaratÄ±cÄ± deÄŸil)

SÄ±caklÄ±k AÃ§Ä±klamasÄ±:
  0.0   â†’ Deterministic (aynÄ± cevap)
  0.5   â†’ Dengeli
  1.0   â†’ Ã‡ok farklÄ± cevaplar
  
  RAG iÃ§in faktual cevaplar istiyoruz â†’ 0.1 ideal

Prompt YapÄ±sÄ±:
  SYSTEM:   "Sen RagBot'sun. Verilen belgelere dayanarak cevap ver."
  
  USER:     "Soru: Python nedir?
             
             Belgeler:
             1. Python gÃ¼Ã§lÃ¼ bir programlama dilidir...
             2. Python web geliÅŸtirme iÃ§in kullanÄ±lÄ±r...
             
             Cevap:"
  
  OUTPUT:   "Python, nesne yÃ¶nelimli, dinamik tipli..."

HÄ±z:      ~1-2 saniye

Ã–nemli:   SÄ±caklÄ±k 0.1 halÃ¼sinasyonlarÄ± engeller. LLM sadece belgelere
          dayanarak cevap veriyor.

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ SOHBET GEÃ‡MÄ°ÅÄ° (Ã‡ok Turlu KonuÅŸma) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

SaklandÄ±ÄŸÄ± yer: PostgreSQL sections tablosu
Format:         JSONB (esnek, aranabilir)

YapÄ±sÄ±:
  {
    messages: [
      {
        question: "Python nedir?",
        answer: "Python, nesne yÃ¶nelimli...",
        sources: ["doc1", "doc2", "doc3"]
      },
      {
        question: "Hangi alanlarda kullanÄ±lÄ±r?",
        answer: "Web, data science, AI...",
        sources: ["doc4", "doc5"]
      }
    ]
  }

Neden JSONB? Esnek ÅŸema, aranabilir, hÄ±zlÄ±
Ã‡ok Turlu: Her yeni soru Ã¶nceki sohbeti gÃ¶rÃ¼yor
           â†’ Daha iyi context â†’ Daha iyi cevaplar

Ã–rnek:
  Soru 1: "Python nedir?"
  Cevap:  "Python programlama dilidir"
  
  Soru 2: "KullanÄ±ldÄ±ÄŸÄ± yerler?"
  LLM:    Soru 1'i de okuyor â†’ daha iyi cevap verebiliyor

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â“ SANA SORULABÄ°LECEK SORULAR
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

S: "RAG sistemi mimarisini aÃ§Ä±kla"
C: "RAG, ilgili belgeleri getirip LLM'ye contexti saÄŸlÄ±yor.
   Sistemimiz iki aÅŸamalÄ±:
   1. pgvector â†’ 10 belgeyi hÄ±zlÄ± bul (85% doÄŸru, <10ms)
   2. Qwen Reranker â†’ En iyi 3'Ã¼ bul (99% doÄŸru, 2-4s)
   EÄŸer Reranker down â†’ fallback mekanizmasÄ± devreye giriyor
   SonuÃ§: Sistem hiÃ§ bozulmaz, her zaman 85%+ doÄŸru."

S: "Neden pgvector VE Reranker ikisi de?"
C: "pgvector 1 milyardan 10'a hÄ±zlÄ± indirir (10ms).
   Reranker bu 10 iÃ§inden en iyisini seÃ§er (2-4s).
   Ä°ki aÅŸama birleÅŸince: hÄ±zlÄ± + doÄŸru.
   Sadece Reranker kullansan â†’ 1 milyardan 3'e gitmek gibi â†’ Ã§ok yavaÅŸ!"

S: "Fallback nasÄ±l Ã§alÄ±ÅŸÄ±yor?"
C: "Reranker genelde 10 belgeyi semantic score'la sÄ±ralar (0-1).
   EÄŸer Reranker down'sa:
   score = 1 - (position * 0.05)
   Position 0 = 1.00, position 5 = 0.75, position 9 = 0.55
   Heuristic ama iÅŸe yarar: pgvector sonuÃ§larÄ± zaten iyi sÄ±ralÄ±."

S: "Neden Cohere kaldÄ±rdÄ±n?"
C: "Cohere fallback'ti ($10-30/ay).
   Vector similarity fallback:
   - Daha hÄ±zlÄ± (10ms vs API latency)
   - Daha ucuz (0$ vs $10-30)
   - Daha gÃ¼venilir (external API yok)
   - Neredeyse aynÄ± iyi (%85 vs %95)
   Zaten %99 doÄŸruluk ile Ã§alÄ±ÅŸÄ±yorken fallback farkÄ± Ã¶nemli deÄŸil."

S: "Neden sÄ±caklÄ±k 0.1?"
C: "LLM randomness'ini kontrol ediyor.
   0.1 = faktual, deterministik (halÃ¼sinasyon azalÄ±r)
   1.0 = yaratÄ±cÄ±, farklÄ± (RAG iÃ§in kÃ¶tÃ¼)
   SÄ±caklÄ±k 0.1 garantiler: LLM belgelere dayanarak cevap verir."

S: "Sohbet geÃ§miÅŸi nedir?"
C: "JSONB format'Ä±nda Q&A Ã§iftleri.
   Her soru Ã¶nceki sorularÄ± gÃ¶rÃ¼r.
   Multi-turn konuÅŸmalar iÃ§in context saÄŸlar.
   BÃ¶ylece LLM 'Ã–nceki soruda sÃ¶yledim' demek gibi ÅŸeyler yapabilir."

S: "Embedding API down olursa?"
C: "Sistem durur. Embedding kritik yol'da fallback yok.
   Mitigation: OpenAI API Ã§ok reliable.
   Alternatif: Local embedding model + cache (maliyet vs gÃ¼venilirlik)."

S: "Fallback score formÃ¼lÃ¼ nedir?"
C: "score = 1 - (index * 0.05)
   Neden? pgvector zaten distance'a gÃ¶re sÄ±ralÄ±.
   Position 0 (en yakÄ±n) â†’ 1.00
   Position 9 (en uzak) â†’ 0.55
   Bu sÄ±ralamayÄ± probability-like score'a Ã§eviriyoruz."

S: "Neden 1536 boyut?"
C: "OpenAI text-embedding-3-small = 1536 boyut.
   BaÅŸka model = baÅŸka boyut (384, 768, 2048 vb.)
   1536 balansÄ±: kalite vs hÄ±z vs depolama."

S: "ZayÄ±f nokta ne?"
C: "Reranker hÄ±zÄ± (2-4s) bottleneck.
   Port 8000 yavaÅŸsa tÃ¼m query yavaÅŸlÄ±yor.
   Ä°zleme Ã¶nemli. Alternatif: daha hÄ±zlÄ± ama daha az doÄŸru reranker."

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ› ï¸ ÃœRETÄ°MDE SORUN GÄ°DERÄ°CÄ°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âŒ Problem: "Sorgular yavaÅŸ (>10 saniye)"

Debug:
  1. Reranker latency'i kontrol et (port 8000)
  2. OpenAI API latency'i kontrol et
  3. pgvector query zamanÄ±nÄ± kontrol et
  
Muhtemel: Reranker yavaÅŸ (2-4s normal). 6s+ ise sorun var.

---

âŒ Problem: "YanlÄ±ÅŸ cevaplar (ilgisiz belgeler kullanÄ±lÄ±yor)"

Debug:
  1. pgvector sonuÃ§larÄ± ilgili mi?
  2. Reranker yeniden sÄ±ralÄ±yor mu?
  3. LLM doÄŸru belgeleri kullandÄ± mÄ±?

Muhtemel: pgvector ilgisiz sonuÃ§lar getiriyor.
Ã‡Ã¶zÃ¼m: LIMIT'i 10'dan 20'ye Ã§Ä±kar (daha fazla seÃ§enek Reranker'a ver)

---

âŒ Problem: "Sistem down/hata"

Debug:
  1. Reranker server Ã§alÄ±ÅŸÄ±yor mu? (curl localhost:8000/health)
  2. PostgreSQL baÄŸlantÄ± ok mi?
  3. OpenAI API cevap veriyor mu?

Beklenen: Reranker down â†’ fallback devreye girmeli (Ã§alÄ±ÅŸmaya devam)
Kontrol: Loglarda "Vector similarity sonuÃ§larÄ± kullanÄ±lÄ±yor" mesajÄ± var mÄ±?

---

âŒ Problem: "YÃ¼ksek token maliyeti"

Debug:
  1. GÃ¼nde kaÃ§ query?
  2. Ortalama embedding boyutu? (~100 token/belge)
  3. LLM context boyutu? (~500-1000 token)

Optimizasyon: 10 belge yerine 3 belge kullan LLM'ye.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š Ä°ZLEME (MONITORING) Ã–LÃ‡ÃœMLERI
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. QUERY GECÄ°KMESÄ° (Latency)
   â”œâ”€ Embedding: ~50ms (tutarlÄ± olmalÄ±)
   â”œâ”€ pgvector: ~10ms (hÄ±zlÄ± olmalÄ±)
   â”œâ”€ Reranker: ~2-4s (normal)
   â”œâ”€ LLM: ~1-2s
   â””â”€ Toplam: ~3-8s
   
   UyarÄ±: >10s ise Reranker/LLM sorunlu

2. FALLBACK ORANI
   â”œâ”€ Ä°zle: Fallback kullanan query'lerin %'si
   â”œâ”€ Normal: <1% (Reranker Ã§ok gÃ¼venilir)
   â”œâ”€ UyarÄ±: >5% (port 8000'de sorun)
   â””â”€ Kritik: >20% (Reranker sÃ¼rekli baÅŸarÄ±sÄ±z)

3. TOKEN KULLANIMI
   â”œâ”€ Ä°zle: GÃ¼nlÃ¼k toplam token
   â”œâ”€ UyarÄ±: Beklenmedik spike (belki inefficient belgeler)
   â””â”€ Tahmini: 1000 query/gÃ¼n = ~500k token/gÃ¼n = ~$0.01

4. CEVAP KALÄ°TESÄ°
   â”œâ”€ Ä°zle: KullanÄ±cÄ± memnuniyeti (ğŸ‘/ğŸ‘)
   â”œâ”€ UyarÄ±: DoÄŸruluk dÃ¼ÅŸÃ¼yor (belgeler eski olabilir)
   â””â”€ Normal: >90% memnuniyet

5. VERÄ°TABANI PERFORMANSI
   â”œâ”€ Ä°zle: pgvector query zamanÄ±
   â”œâ”€ UyarÄ±: >100ms (indexing problemi)
   â””â”€ Takip: VeritabanÄ± boyutu artÄ±yor mÄ±?

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ BÄ°R CÃœMLELÄ°K TANIMLAR
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

RAG:             Belgeler getir sonra LLM ile cevap oluÅŸtur
Embedding:       Metni 1536 sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼r (similarity iÃ§in)
pgvector:        PostgreSQL'de vektÃ¶r arama (hÄ±zlÄ±)
Reranker:        ML modeli dokuman sÄ±ralamak (semantic)
Fallback:        Reranker down ise vektÃ¶r benzerliÄŸi kullan
Cosine Distance: Ä°ki vektÃ¶r arasÄ±nda aÃ§Ä± (benzerlik Ã¶lÃ§er)
BERT:            Attention mekanizmasÄ± (baÄŸlamÄ± anlar)
SÄ±caklÄ±k:        LLM randomness'i (0=sabit, 1=deÄŸiÅŸken)
JSONB:           PostgreSQL JSON (aranabilir, indexlenebilir)
Ã‡ok Turlu:       Sohbet geÃ§miÅŸi tutarak dialog yapma

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… ÃœRETÄ°MÃ–NCESÄ° KONTROL LÄ°STESÄ°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Embedding Ã§alÄ±ÅŸÄ±yor (OpenAI API key geÃ§erli)
âœ… PostgreSQL Ã§alÄ±ÅŸÄ±yor (psql baÄŸlantÄ± ok)
âœ… pgvector extension kurulu (CREATE EXTENSION pgvector)
âœ… Belgeler indexlenmiÅŸ (tÃ¼m PDF'ler embedded ve saklanmÄ±ÅŸ)
âœ… Reranker server Ã§alÄ±ÅŸÄ±yor (curl localhost:8000/health = 200)
âœ… LLM API Ã§alÄ±ÅŸÄ±yor (OpenAI gpt-4o-mini yanÄ±t veriyor)
âœ… Fallback test edildi (Reranker kapalÄ±ken sorgular Ã§alÄ±ÅŸÄ±yor)
âœ… Sohbet geÃ§miÅŸi kaydediliyor (results sections table'da gÃ¶rÃ¼lÃ¼yor)
âœ… Ä°zleme ayarlandÄ± (latency, fallback rate, token kullanÄ±mÄ±)
âœ… Hata handling (500 error yok, graceful degradation var)

ğŸš€ Sistem Ã¼retime hazÄ±r!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ TEKRAR HATIRLATMA: KRÄ°TÄ°K NOKTALAR
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£ pgvector: HIZLI FÄ°LTRE
   â”œâ”€ HÄ±z: <10ms
   â”œâ”€ DoÄŸruluk: 85%
   â”œâ”€ KullanÄ±m: 1M â†’ 10 belge
   â””â”€ Ã–nemli: pgvector zaten iyi sÄ±ralÄ±

2ï¸âƒ£ Reranker: DOÄRU SIRALA
   â”œâ”€ HÄ±z: 2-4s
   â”œâ”€ DoÄŸruluk: 99%
   â”œâ”€ KullanÄ±m: 10 â†’ 3 belge
   â””â”€ Ã–nemli: BERT-like semantic understanding

3ï¸âƒ£ Fallback: BACKUP
   â”œâ”€ Tetikleyici: Reranker down/timeout
   â”œâ”€ HÄ±z: <10ms
   â”œâ”€ DoÄŸruluk: 85%
   â”œâ”€ Formula: 1 - (index * 0.05)
   â””â”€ Ã–nemli: SÄ°STEM HÄ°Ã‡ BOZULMAZ

4ï¸âƒ£ LLM: CEVAP YARAT
   â”œâ”€ Model: gpt-4o-mini
   â”œâ”€ SÄ±caklÄ±k: 0.1 (faktual)
   â”œâ”€ HÄ±z: 1-2s
   â””â”€ Ã–nemli: HalÃ¼sinasyon yok

5ï¸âƒ£ Sohbet: CONTEXT TUTA
   â”œâ”€ Format: JSONB
   â”œâ”€ Depo: PostgreSQL sections
   â”œâ”€ AmaÃ§: Ã‡ok turlu dialog
   â””â”€ Ã–nemli: BaÄŸlam kalÄ±yor

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‰ Bu 5 noktayÄ± anlarsan RAG sistemini anlÄ±yorsun!

Interview'de sorulabilecek herÅŸey buradan Ã§Ä±kÄ±yor.
Production'da sorun Ã§Ä±ksa bunlarÄ± kontrol et.

BaÅŸarÄ±lar! ğŸš€
""")
