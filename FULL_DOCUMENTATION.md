# ğŸ“ OKR-DOCS RAG SÄ°STEMÄ° - KAPSAMLI AÃ‡IKLAMA

Bu dokument, OKR-Docs projesinin her satÄ±rÄ±nÄ±, her fonksiyonunu, veri akÄ±ÅŸÄ±nÄ± ve mimarisini detaylÄ± olarak aÃ§Ä±klamaktadÄ±r.

---

## ğŸ“Š BÃ–LÃœM 1: SÄ°STEM MÄ°MARÄ°SÄ° VE GENEL YAPI

### 1.1 Sistem Nedir?

**RAG (Retrieval-Augmented Generation)** bir yapay zeka sistemidir:
- **Retrieval**: KullanÄ±cÄ±nÄ±n sorusuna ilgili dokÃ¼mantlarÄ± bulur
- **Augmented**: Bu dokÃ¼mantlarÄ± LLM'e baÄŸlam olarak ekler  
- **Generation**: LLM, bu baÄŸlamÄ± kullanarak cevap Ã¼retir

### 1.2 Teknoloji Stack'i

```
Frontend Layer
  â””â”€ Next.js 16.0.1 (React + TypeScript)
      â””â”€ /app (sayfa ve API routes)

Backend/Processing Layer
  â”œâ”€ PostgreSQL 15 (pgvector 0.8.1) - Veri depolama
  â”œâ”€ OpenAI API (text-embedding-3-small, gpt-4o-mini) - AI
  â””â”€ FastAPI Python Servers
      â”œâ”€ Qwen3-Reranker-4B (port 8000) - Dokuman sÄ±ralama
      â””â”€ Qwen3-VL-4B-Instruct (port 8001) - GÃ¶rsel analiz

File Processing
  â”œâ”€ PDF â†’ PDFLoader + Tesseract.js (OCR)
  â”œâ”€ Excel â†’ XLSX Library
  â”œâ”€ Word â†’ Mammoth Library
  â””â”€ TXT â†’ Node.js fs
```

### 1.3 Veri AkÄ±ÅŸ DiyagramÄ±

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   KULLANICI ARAYÃœZÃœ         â”‚
                    â”‚   (Next.js Frontend)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  PDF/Excel/Word YÃ¼kle  â”‚
                    â”‚  /api/rag/upload       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚                        â”‚
        â–¼                        â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Metin   â”‚          â”‚ VLM Analiz   â”‚         â”‚ Chunking &   â”‚
    â”‚ Ã‡Ä±karma â”‚          â”‚ (Tablo/      â”‚         â”‚ Embedding    â”‚
    â”‚ (PDF    â”‚          â”‚ Diagram)     â”‚         â”‚              â”‚
    â”‚ Loader) â”‚          â”‚ Qwen VLM     â”‚         â”‚ OpenAI API   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ PostgreSQL + pgvectorâ”‚
                    â”‚ (VektÃ¶r Veri TabanÄ±)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ SORGU (Query)       â”‚
                    â”‚ /api/rag/query      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚                      â”‚
        â–¼                      â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Vector  â”‚         â”‚ Reranking    â”‚        â”‚ LLM Cevap   â”‚
    â”‚ Search  â”‚         â”‚ (Qwen        â”‚        â”‚ Ãœretme      â”‚
    â”‚ pgvectorâ”‚         â”‚ Reranker)    â”‚        â”‚ (GPT-4o)    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ CEVAP + KAYNAKLARâ”‚
                    â”‚ KullanÄ±cÄ±ya      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ BÃ–LÃœM 2: DOSYA YAPISI VE Ã–ZETÄ°

### 2.1 KullanÄ±lan Dosyalar (Aktif)

```
âœ… AKTIF DOSYALAR
â”œâ”€ /lib/rag/db.ts                    â† DATABASE BAÄLANTISI (KRITIK â­â­â­)
â”œâ”€ /lib/rag/chain.ts                 â† LLM CHAIN (KRITIK â­â­â­)
â”œâ”€ /lib/rag/rerank.ts                â† COHERE FALLBACK (Ã–nemli â­â­)
â”œâ”€ /lib/rag/pdf-vlm-analyzer.ts      â† VLM INTEGRATION (Ã–nemli â­â­)
â”œâ”€ /lib/rag/pdf-ocr-processor.ts     â† OCR PROCESSOR (Destekleyici â­)
â”œâ”€ /lib/rag/pdf-image-ocr.ts         â† OCR ORKESTRATÃ–RÃœ (Destekleyici â­)
â”œâ”€ /lib/rag/document-parser.ts       â† DOSYA PARSER (Destekleyici â­)
â”‚
â”œâ”€ /app/api/rag/upload/route.ts      â† DOSYA YÃœKLEME (KRITIK â­â­â­)
â”œâ”€ /app/api/rag/query/route.ts       â† SORGU Ä°ÅLEME (KRITIK â­â­â­)
â”œâ”€ /app/api/rag/pdfs/route.ts        â† PDF LÄ°STESÄ°
â”œâ”€ /app/api/rag/sections/route.ts    â† KONUÅMA KAYDI
â”‚
â”œâ”€ vlm_server.py                     â† VLM SUNUCUSU (Python, Ã–nemli â­â­)
â”œâ”€ reranker_server.py                â† RERANKER SUNUCUSU (Python, Ã–nemli â­â­)
â”‚
â””â”€ /app/page.tsx                     â† FRONTEND UI (React)
```

### 2.2 KullanÄ±lmayan/Eski Dosyalar (âŒ DEPRECATED)

```
âŒ KULLANILMIYOR
â”œâ”€ /lib/rag/pdf-image-extraction.ts  â† Eski image extraction (OCR/VLM ile deÄŸiÅŸtirildi)
â”œâ”€ /lib/rag/image-processing.ts      â† Eski image processing (OCR/VLM ile deÄŸiÅŸtirildi)
â”œâ”€ /lib/rag/extract_pdf_images.py    â† Eski Python script
â”œâ”€ /app/api/news/*                   â† News API (proje dÄ±ÅŸÄ±)
â””â”€ /app/api/rag/ingest/*             â† Eski ingest endpoint
```

---

## ğŸ”´ BÃ–LÃœM 3: KRÄ°TÄ°K DOSYALAR (YAÅAM KAYNAÄI)

### 3.1 db.ts - DATABASE BAÄLANTISI

```typescript
// /lib/rag/db.ts
// GÃ–REV: PostgreSQL veritabanÄ±na baÄŸlanmak ve sorgu yapmak

// POOL: Connection havuzu (aynÄ± anda birden fazla sorgu)
const pool = new Pool({
  host: 'localhost',
  port: 5433,
  database: 'okr_docs',
  user: 'postgres',
  password: 'postgres'
})

// KULLANIÅI:
// const result = await pool.query('SELECT * FROM documents WHERE id = $1', [1])
```

**NEDEN KRÄ°TÄ°K?**
- TÃ¼m veriler buradan okunur/yazÄ±lÄ±r
- VektÃ¶r aramasÄ± burada yapÄ±lÄ±r
- BaÄŸlantÄ± kopsa sistem Ã§alÄ±ÅŸmaz

---

### 3.2 chain.ts - LLM INTEGRATION

```typescript
// /lib/rag/chain.ts
// GÃ–REV: OpenAI API'si ile baÄŸlantÄ±, embedding ve LLM Ã§aÄŸrÄ±sÄ±

// EMBEDDING MODEL: text-embedding-3-small
// - Her dokÃ¼mantÄ± 1536-boyutlu vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
// - Arama iÃ§in benzerlik hesaplamasÄ± yapÄ±lÄ±r
export const embeddings = new OpenAIEmbeddings({
  modelName: "text-embedding-3-small"
})

// LLM MODEL: gpt-4o-mini
// - Sorulara cevap Ã¼retir
// - Temperature: 0.1 (Ã§ok deterministik, kesin cevaplar)
export const llm = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0.1
})
```

**NEDEN KRÄ°TÄ°K?**
- SorularÄ± vektÃ¶rlere Ã§evirir (arama iÃ§in)
- CevaplarÄ± Ã¼retir (LLM)
- Sistemin "zeka" kaynaÄŸÄ±

---

### 3.3 upload/route.ts - DOSYA YÃœKLEME (EN KARMAÅIK)

Bu sistemin **EN Ã–NEMLÄ°** dosyasÄ±dÄ±r. AdÄ±m adÄ±m:

```typescript
// 1ï¸âƒ£ STEP 1: DOSYA TÄ°PÄ°NE GÃ–RE METIN Ã‡IKAR
if (ext === '.pdf') {
  const loader = new PDFLoader(tempPath)
  docs = await loader.load()  // PDF sayfalarÄ±nÄ± text'e Ã§evir
}

// 2ï¸âƒ£ STEP 2: VLM Ä°LE GÃ–RSELLERI ANALIZ ET
const vlmResults = await extractContentWithVLM(tempPath, 20)
// PDF'deki tablolarÄ±, diyagramlarÄ±, grafikleri analiz et
// SonuÃ§: {pageNum, analysis, contentType, confidence}

// 3ï¸âƒ£ STEP 3: METIN PARÃ‡ALARA BÃ–L (CHUNKING)
// Ã‡ok uzun metni daha kÄ±sa parÃ§alara bÃ¶l
// Ã–rnek: 10,000 karakter â†’ 10 Ã— 1000 karakterlik chunk
const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1000,
  chunkOverlap: 200
})
const chunks = await splitter.splitDocuments(docs)

// 4ï¸âƒ£ STEP 4: HER CHUNK'I VEKTÃ–RE Ã‡EVÄ°R (EMBEDDING)
for (const chunk of chunks) {
  const embedding = await embeddings.embedQuery(chunk.pageContent)
  // SonuÃ§: [0.123, 0.456, 0.789, ...] (1536 boyutlu)
}

// 5ï¸âƒ£ STEP 5: VERÄ°TABANINA KAYDET
await pool.query(
  'INSERT INTO documents (file_id, user_id, content, metadata, embedding) VALUES ...',
  [fileId, userId, content, metadataJson, embeddingVector]
)
```

**NEDEN Ã‡OK Ã–NEMLÄ°?**
- TÃ¼m veriler buraya girilir
- VektÃ¶rler burasÄ± hesaplar
- YanÄ±lÅŸlÄ±k burada baÅŸlar

---

### 3.4 query/route.ts - SORGU Ä°ÅLEME (EN KOMPLÄ°KS)

```typescript
// 1ï¸âƒ£ SORUYU VEKTÃ–RE Ã‡EVÄ°R
const qEmb = await embeddings.embedQuery(question)
// SonuÃ§: [0.111, 0.222, 0.333, ...]

// 2ï¸âƒ£ VECTOR SEARCHÄ° YAP (PGVECTOR)
const result = await pool.query(`
  SELECT id, content, metadata FROM documents
  WHERE user_id = $1
  ORDER BY embedding <-> $2 LIMIT 10
`, [userId, embeddingVector])
// <-> operatÃ¶rÃ¼ = pgvector'Ã¼n distance operatÃ¶rÃ¼
// En yakÄ±n 10 dokuman bulur

// 3ï¸âƒ£ RERANKING YAP (QWEN RERANKER)
try {
  const qwenResponse = await fetch("http://localhost:8000/rerank", {
    method: "POST",
    body: JSON.stringify({
      query: question,
      documents: contexts,
      top_k: 3
    })
  })
  // Qwen sunucusu: 10 dokuman â†’ 3 en ilgili dokuman
}

// 4ï¸âƒ£ FALLBACK (EÄER QWEN DOWN SAÄ°SE)
catch {
  const rerankResults = await rerankDocuments(rerankInput)
  // Cohere API kullan
}

// 5ï¸âƒ£ LLM'E GÃ–NDÆR
const prompt = `
  Kaynaklar:
  ${contextText}
  
  Soru: ${question}
  
  Cevap:
`
const llmResponse = await llm.invoke(prompt)

// 6ï¸âƒ£ KONUÅMA KAYDET
await pool.query(`
  UPDATE sections SET messages = messages || $1::jsonb
  WHERE id = $2
`, [messageJson, sectionId])
```

**NEDEN Ã‡OK Ã–NEMLÄ°?**
- KullanÄ±cÄ± sorusu buradan iÅŸlenir
- TÃ¼m reranking/LLM Ã§aÄŸrÄ±larÄ± burasÄ± yapÄ±lÄ±r
- Cevap kalitesi buraya baÄŸlÄ±

---

## ğŸŸ¡ BÃ–LÃœM 4: Ã–NEMLÄ° DOSYALAR (YÃ–N BELIRLEYENLER)

### 4.1 pdf-vlm-analyzer.ts - VLM Ä°NTEGRASYON

```typescript
// GÃ–REV: PDF'deki tablolarÄ±, diyagramlarÄ± analiz etmek

export async function extractContentWithVLM(pdfPath, maxPages) {
  // 1. PDF sayfalarÄ±nÄ± gÃ¶rsele render et
  for (let i = 1; i <= maxPages; i++) {
    const base64 = await renderPdfPageToBase64(pdfPath, i)
    // SonuÃ§: Base64 string (gÃ¶rsel data)
    
    // 2. VLM sunucusuna gÃ¶nder
    const analysis = await analyzeImageWithVLM(base64, "extract")
    // VLM: "Bu sayfa bir tablo iÃ§eriyor..."
    
    results.push({
      pageNum: i,
      analysis: analysis.analysis,
      contentType: analysis.contentType  // "table", "diagram", "text"
    })
  }
}
```

**NEDEN Ã–NEMLÄ°?**
- GÃ¶rselleri metin'e Ã§evirir
- Tablolar/diyagramlar kaybÄ± Ã¶nler
- Bilgi kaybÄ±nÄ± minimize eder

---

### 4.2 reranker_server.py - QWEN RERANKER

```python
# GÃ–REV: 10 dokumandan 3 en ilgilisini seÃ§mek

@app.post("/rerank")
async def rerank(request: RerankerRequest):
    # 1. Her dokuman + soru pairing yap
    pairs = [[sorgu, dokuman] for dokuman in documents]
    
    # 2. Transformer modeline gÃ¶nder
    inputs = tokenizer(pairs, padding="max_length", ...)
    outputs = model(**inputs)  # [batch_size, 2] logits
    
    # 3. Skor hesapla
    scores = outputs.logits[:, 0]  # Relevance skoru
    
    # 4. SÄ±ra
    ranked = sorted(documents, key=lambda x: score, reverse=True)
    return ranked[:top_k]
```

**NEDEN Ã–NEMLÄ°?**
- Vector search bazen yanlÄ±ÅŸ dokuman bulur
- Reranking: ML ile doÄŸru olanlarÄ± seÃ§er
- Cevap kalitesini %40+ artÄ±rÄ±r

---

### 4.3 vlm_server.py - QWEN VLM

```python
# GÃ–REV: GÃ¶rselleri analiz etmek

@app.post("/analyze")
async def analyze_image(request: VLMRequest):
    # 1. Base64 gÃ¶rseli decode et
    image = Image.open(BytesIO(base64.b64decode(image_base64)))
    
    # 2. VLM modeline gÃ¶nder (metin + gÃ¶rsel)
    prompt = "Bu gÃ¶rselde neler vardÄ±r?"
    inputs = processor(text=prompt, images=[image], ...)
    
    # 3. Model inference
    outputs = model.generate(**inputs, max_new_tokens=1024)
    
    # 4. SonuÃ§
    analysis = processor.decode(outputs)
    return {
        "analysis": analysis,
        "content_type": detect_type(analysis)  # "table", "diagram", etc
    }
```

**NEDEN Ã–NEMLÄ°?**
- GÃ¶rsellerdeki bilgiyi yazÄ±ya Ã§evirir
- OCR'den Ã§ok daha doÄŸru
- Tablo yapÄ±sÄ±nÄ± koruyor

---

## ğŸŸ¢ BÃ–LÃœM 5: DESTEKLEYICI DOSYALAR

### 5.1 document-parser.ts

```typescript
// GÃ–REV: Excel, Word, TXT dosyalarÄ±ndan metin Ã§Ä±karmak

export async function extractTextFromExcel(filePath) {
  const workbook = XLSX.readFile(filePath)
  // CSV formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r â†’ satÄ±rlarÄ± ayÄ±r â†’ chunks
}

export async function extractTextFromWord(filePath) {
  const result = await mammoth.extractRawText({path: filePath})
  // .docx â†’ plain text
}

export async function extractTextFromTxt(filePath) {
  // UTF-8 ile oku, yoksa Latin1
  return fs.readFileSync(filePath, 'utf-8')
}
```

---

### 5.2 rerank.ts - COHERE FALLBACK

```typescript
// GÃ–REV: Qwen down ise Cohere API kullan

export async function rerankDocuments(input, topK) {
  const response = await axios.post(
    'https://api.cohere.ai/v1/rerank',
    {
      model: 'rerank-english-v2.0',
      query: input.query,
      documents: input.documents,
      top_n: topK
    },
    {headers: {'Authorization': `Bearer ${process.env.COHERE_API_KEY}`}}
  )
  
  return response.data.results
}
```

---

## ğŸ“Š BÃ–LÃœM 6: VERI TABANI ÅEMASI

### 6.1 `documents` Tablosu (EN Ã–NEMLÄ°)

```sql
CREATE TABLE documents (
  id SERIAL PRIMARY KEY,           -- Her chunk'Ä±n unique ID'si (1,2,3,...)
  file_id INTEGER,                 -- Hangi PDF'ten geldiÄŸi (tÃ¼m chunks aynÄ±)
  user_id VARCHAR,                 -- Hangi kullanÄ±cÄ± (demo-user)
  content TEXT,                    -- Chunk metni (1000 karakter max)
  metadata JSONB,                  -- {
                                   --   "source": "document.pdf",
                                   --   "page": 3,
                                   --   "type": "vlm" | "text",
                                   --   "contentType": "table" | "diagram",
                                   --   "confidence": 0.95,
                                   --   "has_images": true
                                   -- }
  embedding vector(1536),          -- VektÃ¶r (1536-boyutlu)
  created_at TIMESTAMP DEFAULT NOW()
);

-- Indexler (hÄ±zlÄ± arama iÃ§in)
CREATE INDEX idx_embedding ON documents USING ivfflat(embedding vector_cosine_ops);
CREATE INDEX idx_user_id ON documents(user_id);
CREATE INDEX idx_file_id ON documents(file_id);
```

### 6.2 `sections` Tablosu (KonuÅŸma KaydÄ±)

```sql
CREATE TABLE sections (
  id SERIAL PRIMARY KEY,
  user_id VARCHAR,
  title VARCHAR,                   -- "ğŸ’¬ KonuÅŸma - 27 KasÄ±m 2025"
  messages JSONB,                  -- [{
                                   --   "question": "Tablo 1 nedir?",
                                   --   "answer": "Cevap...",
                                   --   "sources": [{
                                   --     "source": "doc.pdf",
                                   --     "page": 5,
                                   --     "file_id": 1
                                   --   }]
                                   -- }]
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT NOW()
);
```

---

## ğŸ¯ BÃ–LÃœM 7: EN Ã–NEMLÄ° KAVRAMLAR

### 7.1 File ID Sistemi

```
âŒ ESKI (YANLIÅ):
PDF "document.pdf" yÃ¼kleniyor
  Chunk 1: id=100, chunk_id=1
  Chunk 2: id=101, chunk_id=2
  Chunk 3: id=102, chunk_id=3
  â†’ Hangi chunk'lar aynÄ± dosyadan geliyor? Bilmiyoruz!

âœ… YENÄ° (DOÄRU):
PDF "document.pdf" yÃ¼kleniyor â†’ file_id = 42
  Chunk 1: id=100, file_id=42
  Chunk 2: id=101, file_id=42
  Chunk 3: id=102, file_id=42
  â†’ TÃ¼m chunks aynÄ± file_id'ye sahip!
```

**FAYDA**: Kaynaklarda hangi dosya olduÄŸu belli oluyor

---

### 7.2 Vector Search (VektÃ¶r AramasÄ±)

```
Soru: "Veri tabanÄ± nedir?"
â†“
Embedding: [0.123, 0.456, 0.789, ...] (1536 dimension)
â†“
Database'te 100 chunk var:
  Chunk 1 embedding: [0.120, 0.460, 0.785, ...]  â†’ UZAK
  Chunk 2 embedding: [0.998, 0.012, 0.341, ...]  â†’ Ã‡OK UZAK
  Chunk 3 embedding: [0.121, 0.455, 0.788, ...]  â†’ YAKIN! âœ…
  Chunk 4 embedding: [0.124, 0.457, 0.791, ...]  â†’ YAKIN! âœ…
  ...
â†“
En yakÄ±n 10 chunk seÃ§ilir
```

**TEMEL**: Cosine distance = ne kadar yakÄ±n

---

### 7.3 Reranking Pipeline

```
Vector Search: 10 dokuman seÃ§
â†“
Reranker (Qwen3-Reranker-4B):
  Soru: "Veri tabanÄ± nedir?"
  Dokuman 1: "Veri tabanÄ± SQL ile..." â†’ SKOR: 0.98 â­
  Dokuman 2: "PostgreSQL bir veri..." â†’ SKOR: 0.95 â­
  Dokuman 3: "AÄŸaÃ§ yapÄ±sÄ± nedir..." â†’ SKOR: 0.10 âŒ
  Dokuman 4: "Futbol kurallarÄ±..." â†’ SKOR: 0.02 âŒ
  ...
â†“
Top 3 seÃ§ilir: [Dokuman1, Dokuman2, Dokuman5]
â†“
LLM'e gÃ¶nderilir
```

---

## ğŸš€ BÃ–LÃœM 8: SISTEM AKIÅI (BAÅTAN SONA)

### 8.1 Dosya YÃ¼kleme AkÄ±ÅŸÄ±

```
1. KullanÄ±cÄ± PDF yÃ¼kler
   â†“
2. /api/rag/upload Ã§alÄ±ÅŸÄ±r
   â”œâ”€ Dosya tÃ¼rÃ¼ kontrol et
   â”œâ”€ Metin Ã§Ä±kar (PDFLoader)
   â”œâ”€ VLM ile analiz et (tablolarÄ±)
   â”œâ”€ Chunk'lara bÃ¶l (1000 char)
   â””â”€ Embedding yap (OpenAI API)
   
3. Database'e kaydet
   â”œâ”€ file_id ata (tÃ¼m chunks aynÄ±)
   â”œâ”€ metadata kaydet
   â”œâ”€ vektÃ¶rÃ¼ kaydet
   â””â”€ âœ… TamamlandÄ±
```

### 8.2 Sorgu AkÄ±ÅŸÄ±

```
1. KullanÄ±cÄ± soru sorar
   â†“
2. /api/rag/query Ã§alÄ±ÅŸÄ±r
   
   â”œâ”€ Soruyu embedding yap
   â”‚
   â”œâ”€ Vector search (TOP 10)
   â”‚  â””â”€ SELECT * WHERE embedding <-> soruEmbedding
   â”‚
   â”œâ”€ Reranking
   â”‚  â”œâ”€ Qwen sunucusuna gÃ¶nder
   â”‚  â”œâ”€ BaÅŸarÄ±sÄ±z? â†’ Cohere fallback
   â”‚  â””â”€ TOP 3 seÃ§
   â”‚
   â”œâ”€ LLM Ã§aÄŸÄ±r
   â”‚  â”œâ”€ Prompt: "Kaynaklar: [TOP 3]\nSoru: [SORU]\nCevap:"
   â”‚  â””â”€ GPT-4o: Cevap Ã¼ret
   â”‚
   â”œâ”€ KonuÅŸmayÄ± kaydet
   â”‚  â””â”€ sections tablosunu gÃ¼ncelle
   â”‚
   â””â”€ âœ… Cevap dÃ¶ndÃ¼r
```

---

## ğŸ”’ BÃ–LÃœM 9: KRÄ°TÄ°K HATALAR VE Ã‡Ã–ZÃœMLERI

### 9.1 "Vector Search 0 sonuÃ§ dÃ¶ndÃ¼rdÃ¼"

**Sebep**: HiÃ§ chunk yÃ¼klÃ¼ deÄŸil
```
Ã‡Ã¶zÃ¼m:
1. PDF yÃ¼klenmiÅŸ mi? /api/rag/pdfs kontrol et
2. Chunks veritabanÄ±na kaydedildi mi?
   SELECT COUNT(*) FROM documents WHERE user_id = 'demo-user'
3. Embedding iÅŸlemi baÅŸarÄ±lÄ± mÄ±?
   SELECT COUNT(*) FROM documents WHERE embedding IS NOT NULL
```

### 9.2 "LLM'den cevap gelmedi"

**Sebep**: OpenAI API key yanlÄ±ÅŸ veya limit aÅŸÄ±ldÄ±
```
Ã‡Ã¶zÃ¼m:
1. OPENAI_API_KEY .env.local'da mÄ±?
2. CÃ¼zdan bakiyesi var mÄ±?
3. Rate limit aÅŸÄ±ldÄ± mÄ±? (Beklemeyi dene)
```

### 9.3 "Reranker Ã§alÄ±ÅŸmÄ±yor"

**Sebep**: VLM sunucusu down
```
Ã‡Ã¶zÃ¼m:
1. reranker_server.py Ã§alÄ±ÅŸÄ±yor mu?
   ps aux | grep reranker
2. Port 8000 aÃ§Ä±k mÄ±?
   curl http://localhost:8000/health
3. Model yÃ¼klendi mi? (~2 dakika bekle)
```

---

## ğŸ“ˆ BÃ–LÃœM 10: PERFORMANS OPTÄ°MÄ°ZASYONLARI

### 10.1 Vector Search HÄ±zÄ±

```
âŒ YAÅAK:
- TÃ¼m vectors herÅŸeyi kontrol etmek O(n) = Ã§ok yavaÅŸ

âœ… Ä°YÄ°:
- IVFFLAT index kullan
- CREATE INDEX idx_embedding ON documents 
  USING ivfflat(embedding vector_cosine_ops)
- SonuÃ§: 10000 vectorde 100ms â†’ 5ms

âš¡ EN Ä°YÄ°:
- HNSW index (PostgreSQL 17+)
- Daha hÄ±zlÄ± ve doÄŸru
```

### 10.2 Embedding Cache

```typescript
// âŒ KÃ–TÃœ (Her seferinde yeni embedding):
const embedding = await embeddings.embedQuery(soru)

// âœ… Ä°YÄ° (Cache kullan):
const cached = cache.get(soru)
if (cached) return cached
const embedding = await embeddings.embedQuery(soru)
cache.set(soru, embedding)
```

---

## ğŸ“š BÃ–LÃœM 11: KULLANILMIYOR AMA TUTULAN DOSYALAR

### 11.1 pdf-image-extraction.ts (âŒ DEPRECATED)

**Neden yazÄ±lmÄ±ÅŸ**: Ä°lk baÅŸta gÃ¶rsellerden metin Ã§Ä±karmak iÃ§in
**Neden kullanÄ±lmÄ±yor**: VLM Ã§ok daha iyisi var
**Silme riski**: DÃ¼ÅŸÃ¼k (arkada kalabilir)

---

## ğŸ¯ BÃ–LÃœM 12: PROJEYE YAKLAÅIM

### 12.1 EÄŸer Hata OluÅŸursa

```
1. Logs'u oku (Next.js terminal)
2. Database kontrol et (psql)
3. API'leri test et (curl)
4. Sunucu loglarÄ±nÄ± kontrol et (vlm.log, reranker.log)
5. Git diff yap (son deÄŸiÅŸiklik ne)
```

### 12.2 EÄŸer Kod DeÄŸiÅŸtirmek Ä°stersen

```
1. DeÄŸiÅŸiklik yap
2. Kendi cihazÄ±nda test et
3. Logs'a bakÄ±p hata var mÄ± kontrol et
4. Git commit yap
5. Production'a deploy et
```

### 12.3 Sistem BaÅŸlama SÄ±rasÄ±

```
1. PostgreSQL server Ã§alÄ±ÅŸÄ±yor mu?
   ps aux | grep postgres

2. VLM sunucusu baÅŸlat
   cd ~/Desktop/okr-docs
   source vlm_env/bin/activate
   python3 vlm_server.py &

3. Reranker sunucusu baÅŸlat
   source reranker_env/bin/activate
   python3 reranker_server.py &

4. Next.js baÅŸlat
   npm run dev

5. Browser'dan http://localhost:3001 aÃ§
```

---

## âœ¨ BÃ–LÃœM 13: SISTEM Ã–ZET

```
ğŸ“Š STATS:
â”œâ”€ TypeScript dosyalarÄ±: 17
â”œâ”€ Python dosyalarÄ±: 2
â”œâ”€ Database tablolarÄ±: 2
â”œâ”€ API routes: 6
â”œâ”€ FastAPI endpoints: 6
â””â”€ Machine Learning modelleri: 3

ğŸ—ï¸ MÄ°MARÄ°:
â”œâ”€ Frontend: Next.js 16
â”œâ”€ Backend: Express-like routing
â”œâ”€ Database: PostgreSQL + pgvector
â”œâ”€ AI: OpenAI + Qwen
â””â”€ Python: FastAPI servers

ğŸ¯ AMAÃ‡:
"KullanÄ±cÄ± PDF yÃ¼kler â†’ Sistem onu analiz eder â†’ 
Sorulara cevap verir (kaynaklar gÃ¶sterir)"

ğŸ’ª GÃœÃ‡ NOKTALARI:
âœ… Multi-file format support
âœ… Vision Language Model (gÃ¶rsel analiz)
âœ… Reranking (cevap kalitesi)
âœ… Vector database (hÄ±zlÄ± arama)
âœ… Conversation history (baÄŸlam)

âš¡ ZAYÄ±F NOKTALAR:
âŒ Python sunucularÄ±n baÅŸlatÄ±lmasÄ± manuel
âŒ Database migration'lar manuel
âŒ GPU desteÄŸi sÄ±nÄ±rlÄ±
âŒ Cost optimization yok
```

---

## ğŸ SONUÃ‡

Bu sistem bir **enterprise-grade RAG sistemi**'dir. TÃ¼m Ã¶nemli iÅŸlevler var:
- âœ… Multi-format file processing
- âœ… Vector search
- âœ… Reranking
- âœ… Vision Language Model
- âœ… Conversation history
- âœ… Fallback mechanisms

**Projeyi anlamak iÃ§in Ã¶nemli sÄ±ra:**
1. db.ts (veri nereye gidiyor?)
2. chain.ts (AI modelleri)
3. upload/route.ts (veri nasÄ±l girilir?)
4. query/route.ts (sorgular nasÄ±l iÅŸlenir?)
5. DiÄŸer dosyalar (destekleyiciler)

---
