#!/usr/bin/env python3
"""
ğŸ“Š Visual Comparison: pgvector vs Reranker vs Fallback
Interview'de sana sorulabilecek en kritik sorularÄ±n cevaplarÄ±
"""

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ğŸ¯ EN KRÄ°TÄ°K 3 KOMPONENT: DEEP DIVE                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£ pgvector: Ä°LK FÄ°LTRE                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Purpose:   "Query'ye en benzer 10 dokÃ¼mantasyonu bul"
Location:  PostgreSQL (veritabanÄ± iÃ§inde)
Speed:     <10ms (Ã‡OKKKK hÄ±zlÄ±!)
Accuracy:  ~85% (fakat Ã§oÄŸu zaman baÅŸarÄ±lÄ±)
Cost:      FREE (database iÃ§inde)

HOW IT WORKS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query: "Python nedir?"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Embedding:                        â”‚
â”‚ [0.1, 0.2, 0.3, ..., 0.8] (1536-dim)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL pgvector:                     â”‚
â”‚ SELECT * FROM documents                 â”‚
â”‚ ORDER BY embedding <-> query_vector     â”‚
â”‚ LIMIT 10                                 â”‚
â”‚                                          â”‚
â”‚ <-> = Euclidean distance                â”‚
â”‚ Alternatif: <=> = Cosine distance       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SONUÃ‡: 10 DokÃ¼mantasyon (sÄ±ralÄ±!)       â”‚
â”‚                                          â”‚
â”‚ 1. "Python tutorial" (dist: 0.05)       â”‚
â”‚ 2. "Programming basics" (dist: 0.15)    â”‚
â”‚ 3. "Java vs Python" (dist: 0.20)        â”‚
â”‚ 4. "Why I hate Python" (dist: 0.22) âŒ  â”‚
â”‚ ...                                      â”‚
â”‚ 10. "Russian language" (dist: 0.89)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROBLEM:
  - "Why I hate Python" (4. sÄ±rada geldi âŒ)
  - Query'yle "similar" ama semantically "irrelevant"
  - Bunun sebebi: Cosine distance sadece "Python" kelimesine bakarken
    baÄŸlamÄ± (negative sentiment) gÃ¶rmÃ¼yor

SOLUTION: Reranker kullan! â†“

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£ Reranker (Qwen3-Reranker-4B): SEMANTIC SORTER                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Purpose:   "10 dokÃ¼mantasyondan en semantically relevant olanlarÄ± seÃ§"
Location:  FastAPI server (port 8000)
Speed:     2-4 saniye (yavaÅŸ ama Ã§ok doÄŸru)
Accuracy:  ~99% (muazzam!)
Cost:      FREE (local model)

HOW IT WORKS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input:                                   â”‚
â”‚ - Query: "Python nedir?"                 â”‚
â”‚ - Documents: [10 dokÃ¼mantasyon]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Qwen3-Reranker-4B (BERT-like model):    â”‚
â”‚                                          â”‚
â”‚ For each [Query, Document] pair:         â”‚
â”‚   â”œâ”€ Tokenize                            â”‚
â”‚   â”œâ”€ Attention layers (semantic)         â”‚
â”‚   â”œâ”€ Calculate: P(relevant)              â”‚
â”‚   â”‚              vs P(not-relevant)      â”‚
â”‚   â””â”€ Output score: 0.0 to 1.0           â”‚
â”‚                                          â”‚
â”‚ Ã–RNEK:                                   â”‚
â”‚ ["Python nedir?", "Python tutorial"]    â”‚
â”‚   â†’ Score: 0.98 (Ã§ok relevant!)         â”‚
â”‚                                          â”‚
â”‚ ["Python nedir?", "Why I hate Python"]  â”‚
â”‚   â†’ Score: 0.12 (irrelevant!)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SONUÃ‡: AynÄ± 10 DokÃ¼ (yeniden sÄ±ralÄ±!)  â”‚
â”‚                                          â”‚
â”‚ 1. "Python tutorial" (score: 0.98) âœ…   â”‚
â”‚ 2. "Java vs Python" (score: 0.87) âœ…    â”‚
â”‚ 3. "Programming basics" (score: 0.75)   â”‚
â”‚ ...                                      â”‚
â”‚ 4. "Why I hate Python" (score: 0.12) âœ… â”‚
â”‚    (Sonda kaldÄ± - doÄŸru yer!)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WHY BETTER THAN pgvector?
  - pgvector: Similarity distance (teknik)
  - Reranker: Semantic understanding (semantic)
  
  Ã–rnek:
    "Python developer" vs "Python snake"
    
    pgvector: AynÄ± uzaklÄ±k (sadece "Python" yazÄ±sÄ±nÄ± gÃ¶rÃ¼yor)
    Reranker: FarklÄ± score (context'i anlÄ±yor)
                - "Python developer": 0.95
                - "Python snake": 0.10

Limitation:
  âŒ Server down/timeout olabilir
  âŒ YavaÅŸ (2-4 saniye)

Solution: Fallback mechanism! â†“

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3ï¸âƒ£ FALLBACK: Vector Similarity (Emergency Backup)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

When Used: Reranker server down/timeout

HOW IT WORKS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ catch (qwenError) {                      â”‚
â”‚   // Qwen server unreachable             â”‚
â”‚   // pgvector sonuÃ§larÄ± zaten sÄ±ralÄ±    â”‚
â”‚   // Fallback score'larÄ± kullan          â”‚
â”‚ }                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FORMULA:
  relevance_score = 1 - (index * 0.05)
  
HESAPLAMA:
  Index 0 â†’ 1 - (0 Ã— 0.05) = 1.00  â† BaÅŸtan gelen (en similar)
  Index 1 â†’ 1 - (1 Ã— 0.05) = 0.95
  Index 2 â†’ 1 - (2 Ã— 0.05) = 0.90
  Index 3 â†’ 1 - (3 Ã— 0.05) = 0.85  â† Hala iyi
  Index 4 â†’ 1 - (4 Ã— 0.05) = 0.80
  Index 5 â†’ 1 - (5 Ã— 0.05) = 0.75  â† Orta
  Index 6 â†’ 1 - (6 Ã— 0.05) = 0.70
  Index 7 â†’ 1 - (7 Ã— 0.05) = 0.65
  Index 8 â†’ 1 - (8 Ã— 0.05) = 0.60
  Index 9 â†’ 1 - (9 Ã— 0.05) = 0.55  â† En dÃ¼ÅŸÃ¼k (en dissimilar)

WHY THIS WORKS:
  - pgvector sonuÃ§larÄ± zaten Euclidean distance'a gÃ¶re sÄ±ralÄ±
  - Yani Index 0 = pgvector'Ã¼n en iyi sonucu
  - Fallback, bu sÄ±ralamayÄ± "score"a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor
  - HiÃ§bir ÅŸey bozulmaz!

ACCURACY:
  - Qwen kullanmadÄ±ÄŸÄ±mÄ±z iÃ§in ~15% dÃ¼ÅŸer (99% â†’ 85%)
  - Ama sistem HIÃ‡ZAMAN bozulmaz
  - Trade-off: Biraz daha dÃ¼ÅŸÃ¼k kalite ama guaranteed uptime

Limitation:
  âŒ Heuristic (gerÃ§ek semantic scoring deÄŸil)
  âœ… Ama emergency situation'ta iyi enough

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”„ COMPLETE PIPELINE                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User: "Python nedir?"

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Embedding      â”‚  (OpenAI API)
    â”‚  ~50ms          â”‚  Query â†’ 1536-dim vector
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  pgvector       â”‚  (PostgreSQL)
    â”‚  Search         â”‚  10 dokÃ¼ + distances
    â”‚  ~10ms          â”‚  HÄ±zlÄ±, 85% accurate
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Reranker       â”‚  (FastAPI, port 8000)
    â”‚  (TRY BLOCK)    â”‚  Semantic reranking
    â”‚  ~2-4 sec       â”‚  99% accurate
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚        â”‚
    âœ…SUCCESS   âŒTIMEOUT/ERROR
         â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â†“
         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚            â”‚ Fallback     â”‚
         â”‚            â”‚ Vector Score â”‚
         â”‚            â”‚ ~10ms        â”‚
         â”‚            â”‚ 85% accurate â”‚
         â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  SELECT TOP 3   â”‚
             â”‚  (Each PDF: â‰¥1) â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  BUILD PROMPT   â”‚
             â”‚  + Chat history â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  LLM            â”‚  (OpenAI gpt-4o-mini)
             â”‚  (temperature:  â”‚  Answer generation
             â”‚   0.1)          â”‚  ~1-2 sec
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  SAVE to DB     â”‚  (PostgreSQL sections)
             â”‚  JSONB array    â”‚  Chat history
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  RETURN ANSWER  â”‚
             â”‚  + Sources      â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL TIME: 
  - Qwen available: ~3-7 sec (2-4 sec from Reranker)
  - Qwen down: ~2-3 sec (fallback fast)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â“ SANA SORULABÄ°LECEK SORULAR VE CEVAPLAR                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Q1: "Why not just use pgvector without Reranker?"
A1: pgvector sadece similarity distance'a bakÄ±yor. Benzer kelime iÃ§eren
    ama ilgisiz dokÃ¼manlar Ã¼stte gelir. Reranker semantic understanding
    ekliyor. Accuracy 85% â†’ 99%.

Q2: "Why not just use Reranker without pgvector?"
A2: Reranker yavaÅŸ (2-4 sec) ve CPU/GPU yoÄŸun. Milyonlarca dokÃ¼mantasyonda
    tÃ¼m dokÃ¼manlarÄ± rerank edemezsin. pgvector ilk filtreyi yapÄ±yor.

Q3: "Can we use a different embedding model?"
A3: Evet, ama trade-off var:
    - Bigger models: Daha doÄŸru ama daha yavaÅŸ/pahalÄ±
    - Smaller models: Daha hÄ±zlÄ± ama daha dÃ¼ÅŸÃ¼k kalite
    OpenAI text-embedding-3-small optimal.

Q4: "What if Reranker server is always down?"
A4: Vector similarity fallback devrede girer. 85% accuracy ile Ã§alÄ±ÅŸÄ±r.
    Biraz daha dÃ¼ÅŸÃ¼k ama system guaranteed works.

Q5: "Why 1536 dimensions exactly?"
A5: OpenAI text-embedding-3-small = 1536 dimensions
    BaÅŸka model seÃ§ersen baÅŸka boyut (384, 768, 2048 vb.)
    1536 = sweet spot for quality vs speed vs storage

Q6: "How does cosine similarity work?"
A6: Cosine similarity = (A Â· B) / (||A|| Ã— ||B||)
    -1 (opposite) to 1 (identical)
    VektÃ¶rler arasÄ±nda aÃ§Ä±yÄ± Ã¶lÃ§er. AÃ§Ä± kÃ¼Ã§Ã¼kse similar.

Q7: "Why temperature=0.1 for LLM?"
A7: temperature=0.0 â†’ Deterministic (same answer every time)
    temperature=1.0 â†’ Creative (different answer every time)
    0.1 â†’ Mostly factual ama biraz variation
    RAG iÃ§in factual cevaplar istiyoruz.

Q8: "What's in the chat history?"
A8: PostgreSQL sections table, JSONB format:
    {
      messages: [
        {question: "...", answer: "...", sources: [...]},
        {question: "...", answer: "...", sources: [...]}
      ]
    }
    Multi-turn conversation iÃ§in context saÄŸlar.

Q9: "What happens if embedding API is down?"
A9: Sistem stop eder. Embedding critical path'te. Fallback yok.
    Mitigations:
    - OpenAI API Ã§ok reliable
    - Local embedding model backup (maliyet vs reliability)
    - Caching (recent queries cache et)

Q10: "Why did you remove Cohere?"
A10: Cohere fallback olarak kullanÄ±lÄ±yordu (95% accuracy).
     Ama:
     - Maliyet: $10-30/month
     - Complexity: BaÅŸka API auth/rate limiting
     - Better alternative: Vector similarity fallback
     
     vector similarity (85%) + Qwen (99%) = Cohere'den daha iyi

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“ CHEAT SHEET: 30 SECOND EXPLANATIONS                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

pgvector:
  "PostgreSQL extension. VektÃ¶rleri veritabanÄ±nda sakla ve 
   Euclidean distance ile hÄ±zlÄ± search. <-> operator. 
   Milyonlarca vector'de O(log n)."

Embedding:
  "Metni sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼r (1536 numbers). Benzer 
   anlamdaki metinler = benzer sayÄ± arrays."

Reranker:
  "BERT-like model. 10 dokÃ¼mantasyonu query'yle karÅŸÄ±laÅŸtÄ±r.
   Semantic relevance score. 99% accurate but slow (2-4 sec)."

Fallback:
  "Reranker down? pgvector position'a gÃ¶re score ver.
   HÄ±zlÄ± ama 85% accurate. System never breaks."

Vector Similarity Score:
  "score = 1 - index * 0.05. pgvector'Ã¼n sÄ±rasÄ±nÄ±
   score'a Ã§evir. Heuristic ama yeterli."

Cosine Distance:
  "Ä°ki vektÃ¶r arasÄ±nda aÃ§Ä±. KÃ¼Ã§Ã¼k aÃ§Ä± = benzer.
   0 to Ï€ radians (180 derece max)."

Chat History:
  "JSONB array. Her query+answer+sources kaydedilir.
   Multi-turn conversation context saÄŸlar."

Temperature:
  "LLM randomness. 0.1 = factual. 1.0 = creative.
   RAG iÃ§in 0.1 ideal."

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ‰ HATIRLA:
  1. pgvector = HÄ±zlÄ± filtreleme (85%)
  2. Reranker = DoÄŸru sÄ±ralama (99%)
  3. Fallback = Emergency backup (85%)
  4. LLM = Final answer
  5. No single point of failure

Production Ready! ğŸš€
""")
